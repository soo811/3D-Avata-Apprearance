{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd10f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291a2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    globals()['land'+str(i)] = pd.read_csv('./dlib1000/train/%s.csv'%i)\n",
    "    globals()['land'+str(i)] = np.array(globals()['land'+str(i)])\n",
    "    \n",
    "    tr_x = globals()['land'+str(i)][:, 0]\n",
    "    tr_y = globals()['land'+str(i)][:, 1]\n",
    "    \n",
    "    tr_cx = ((min(tr_x)+max(tr_x)) / 2)        #dlib_rect 중점\n",
    "    tr_cy = ((min(tr_y)+max(tr_y)) / 2)\n",
    "    \n",
    "    tr_h = max(tr_y)-min(tr_y)    #종축 길이\n",
    "    \n",
    "    tr_x -= tr_cx\n",
    "    tr_y -= tr_cy\n",
    "    \n",
    "    norm_trx = (tr_x - min(tr_x)) / (tr_h * 1.5)\n",
    "    norm_try = (tr_y - min(tr_y)) / (tr_h *1.5)\n",
    "    \n",
    "    globals()['train_norm'+str(i)] = np.column_stack((norm_trx, norm_try))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6371d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## eye, nose, mouth, jaws\n",
    "for i in  range(1000):\n",
    "    globals()['norm_eye'+str(i)] = globals()['train_norm'+str(i)][36:48].flatten()\n",
    "    globals()['norm_nose'+str(i)] = globals()['train_norm'+str(i)][27:36].flatten()\n",
    "    globals()['norm_mouth'+str(i)] = globals()['train_norm'+str(i)][48:].flatten()\n",
    "    globals()['norm_jaws'+str(i)] = globals()['train_norm'+str(i)][:17].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fb71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros((1000, len(norm_eye0)))   #eye\n",
    "for i in range(1000):\n",
    "    for j in range(len(norm_eye0)):\n",
    "        train_x[i][j] = globals()['norm_eye'+str(i)][j]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8dca09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_eye = pd.read_csv('./DataSet1000/train/csv/train.csv')\n",
    "try_eye = try_eye.iloc[:, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24556e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    globals()['mark'+str(i)] = pd.read_csv('./dlib1000/test/%s.csv'%i)\n",
    "    globals()['mark'+str(i)] = np.array(globals()['mark'+str(i)])\n",
    "    \n",
    "    te_x = globals()['mark'+str(i)][:, 0]\n",
    "    te_y = globals()['mark'+str(i)][:, 1]\n",
    "    \n",
    "    te_cx = ((min(te_x)+max(te_x)) / 2)\n",
    "    te_cy = ((min(te_y)+max(te_y)) / 2)\n",
    "\n",
    "    te_h = max(te_y)-min(te_y)\n",
    "    \n",
    "    \n",
    "    te_x -= te_cx\n",
    "    te_y -= te_cy\n",
    "\n",
    "    norm_tex = (te_x - min(te_x)) / (te_h *1.5)\n",
    "    norm_tey = (te_y - min(te_y)) / (te_h *1.5)\n",
    "    \n",
    "    globals()['test_norm'+str(i)] = np.column_stack((norm_tex, norm_tey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22a9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## eye, nose, mouth, jaws\n",
    "for i in  range(1000):\n",
    "    globals()['norm_eye2'+str(i)] = globals()['test_norm'+str(i)][36:48].flatten()\n",
    "    globals()['norm_nose2'+str(i)] = globals()['test_norm'+str(i)][27:36].flatten()\n",
    "    globals()['norm_mouth2'+str(i)] = globals()['test_norm'+str(i)][48:].flatten()\n",
    "    globals()['norm_jaws2'+str(i)] = globals()['test_norm'+str(i)][:17].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352bfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.zeros((1000, len(norm_eye20)))\n",
    "for i in range(1000):\n",
    "    for j in range(len(norm_eye20)):\n",
    "        test_x[i][j] = globals()['norm_eye2'+str(i)][j]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35101a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tey_eye = pd.read_csv('./DataSet1000/test/csv/test.csv')\n",
    "tey_eye = tey_eye.iloc[:, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8c5816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "learning_rate = 0.001\n",
    "N_EPOCHS = 500\n",
    "N_BATCH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95686b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, try_eye))\\\n",
    "                                .shuffle(500)\\\n",
    "                                .batch(N_BATCH, drop_remainder=True)\\\n",
    "                                .repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, tey_eye)).batch(N_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aab604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6434fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu', input_shape=(24,)))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "#     model.add(keras.layers.Dense(units=16, activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aa03304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1474dc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                1600      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,713\n",
      "Trainable params: 3,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "800c1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_x.shape[0]\n",
    "validation_steps = int(np.ceil(test_x.shape[0]/N_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18afd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# filename = 'checkpoint={epoch:02d}-{val_loss:.5f}.h5'\n",
    "\n",
    "# reduceLR =ReduceLROnPlateau(monitor='val_loss', factor=0.5, mode='min')\n",
    "# checkpoint = ModelCheckpoint(filename, monitor='val_loss', verboss=1, save_best_only=True, mode='min')\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "# callbacks_list = [reduceLR, checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01a11962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5e2090c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 1s 646us/step - loss: 0.0836 - accuracy: 0.0000e+00 - val_loss: 0.0837 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0764 - accuracy: 0.0000e+00 - val_loss: 0.0809 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0721 - accuracy: 0.0000e+00 - val_loss: 0.0799 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0644 - accuracy: 0.0000e+00 - val_loss: 0.0696 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0540 - accuracy: 0.0000e+00 - val_loss: 0.0520 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0437 - accuracy: 0.0000e+00 - val_loss: 0.0588 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0402 - accuracy: 0.0000e+00 - val_loss: 0.0456 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0391 - accuracy: 0.0000e+00 - val_loss: 0.0399 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0396 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0410 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0391 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0386 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0379 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0399 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0387 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0380 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0376 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0434 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0367 - accuracy: 0.0000e+00 - val_loss: 0.0378 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0365 - accuracy: 0.0000e+00 - val_loss: 0.0382 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0363 - accuracy: 0.0000e+00 - val_loss: 0.0404 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0364 - accuracy: 0.0000e+00 - val_loss: 0.0373 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0433 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0425 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0369 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0386 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0424 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0356 - accuracy: 0.0000e+00 - val_loss: 0.0367 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0429 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0360 - accuracy: 0.0000e+00 - val_loss: 0.0370 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0370 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0384 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0367 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0362 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0353 - accuracy: 0.0000e+00 - val_loss: 0.0387 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0425 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0413 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0366 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0418 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0368 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.0364 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0348 - accuracy: 0.0000e+00 - val_loss: 0.0363 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0380 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0343 - accuracy: 0.0000e+00 - val_loss: 0.0523 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0333 - accuracy: 0.0000e+00 - val_loss: 0.0383 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0332 - accuracy: 0.0000e+00 - val_loss: 0.0364 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0331 - accuracy: 0.0000e+00 - val_loss: 0.0371 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0334 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0333 - accuracy: 0.0000e+00 - val_loss: 0.0379 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0332 - accuracy: 0.0000e+00 - val_loss: 0.0373 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0336 - accuracy: 0.0000e+00 - val_loss: 0.0385 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0332 - accuracy: 0.0000e+00 - val_loss: 0.0361 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0329 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0336 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0329 - accuracy: 0.0000e+00 - val_loss: 0.0367 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0332 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0329 - accuracy: 0.0000e+00 - val_loss: 0.0410 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0330 - accuracy: 0.0000e+00 - val_loss: 0.0365 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0320 - accuracy: 0.0000e+00 - val_loss: 0.0369 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0322 - accuracy: 0.0000e+00 - val_loss: 0.0383 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0322 - accuracy: 0.0000e+00 - val_loss: 0.0358 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0320 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0320 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0322 - accuracy: 0.0000e+00 - val_loss: 0.0357 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0321 - accuracy: 0.0000e+00 - val_loss: 0.0357 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0320 - accuracy: 0.0000e+00 - val_loss: 0.0382 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0321 - accuracy: 0.0000e+00 - val_loss: 0.0368 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.0371 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0320 - accuracy: 0.0000e+00 - val_loss: 0.0376 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.0357 - val_accuracy: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0316 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0313 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0315 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0313 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0313 - accuracy: 0.0000e+00 - val_loss: 0.0371 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0369 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0313 - accuracy: 0.0000e+00 - val_loss: 0.0358 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0314 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0312 - accuracy: 0.0000e+00 - val_loss: 0.0365 - val_accuracy: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0311 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0354 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0354 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0309 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0355 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0310 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0309 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0354 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0354 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0309 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0309 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.1250e-05\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0308 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5625e-05\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 7.8125e-06\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.9063e-06\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 143/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9531e-06\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.7656e-07\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.8828e-07\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.4414e-07\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.2207e-07\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 6.1035e-08\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.0518e-08\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.5259e-08\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 1s 631us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 1s 661us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.6294e-09\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.8147e-09\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.9073e-09\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 1s 646us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 1s 629us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.5367e-10\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 1s 639us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.7684e-10\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 1s 619us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 1s 614us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3842e-10\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1921e-10\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.9605e-11\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9802e-11\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4901e-11\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.4506e-12\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.7253e-12\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8626e-12\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.3132e-13\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.6566e-13\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.3283e-13\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1642e-13\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.8208e-14\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.9104e-14\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.4552e-14\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 425/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 7.2760e-15\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 3.6380e-15\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.8190e-15\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 9.0949e-16\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 4.5475e-16\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 1s 619us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.2737e-16\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0307 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0305 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 1.1369e-16\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 5.6843e-17\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.8422e-17\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.8422e-17\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0306 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - lr: 2.8422e-17\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                   epochs=N_EPOCHS,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   validation_data = test_dataset,\n",
    "                   validation_steps = validation_steps,\n",
    "                   callbacks=[reduceLR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbfe2a26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 581us/step - loss: 0.0352 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)\n",
    "\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3dd458dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAJaCAYAAADDK72aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEOUlEQVR4nO3deXhU5f3+8fvMnn0hkLCETZFVUMEFlNa6oLjVqtW2VuVbtT+q1iq1tmoXtQtdrFKrYKvSaje1daltaQWtIooWUUAEZJElARJCCNmTWc/vj5OZzCSTsAVmTni/ritXZs6cmXkmGULufJ7n8ximaZoCAAAAABwSR6oHAAAAAAC9AeEKAAAAAHoA4QoAAAAAegDhCgAAAAB6AOEKAAAAAHoA4QoAAAAAegDhCgAAAAB6AOEKAAAAAHqAK9UDSEeRSEQ7d+5UTk6ODMNI9XAAAAAApIhpmmpoaNCAAQPkcHRfmyJcJbFz506VlpamehgAAAAA0kR5ebkGDRrU7TmEqyRycnIkWV/A3NzcFI8GAAAAQKrU19ertLQ0lhG6Q7hKIjoVMDc3l3AFAAAAYL+WC9HQAgAAAAB6AOEKAAAAAHoA4QoAAAAAegBrrgAAAGBL4XBYwWAw1cNAL+B2u+V0Og/5cQhXAAAAsJ3GxkZt375dpmmmeijoBQzD0KBBg5SdnX1Ij0O4AgAAgK2Ew2Ft375dmZmZ6tu37351cQO6Ypqmdu/ere3bt2vEiBGHVMEiXAEAAMBWgsGgTNNU3759lZGRkerhoBfo27evtm7dqmAweEjhioYWAAAAsCUqVugpPfVeIlwBAAAAQA8gXAEAAABADyBcAQAAADY0dOhQzZkzJ+WPgXY0tAAAAACOgDPPPFMnnHBCj4WZ9957T1lZWT3yWOgZhCsAAAAgTZimqXA4LJdr37+m9+3b9wiMCAeCaYEAAACwNdM01RwIpeRjfzcxnjFjhhYvXqxf/epXMgxDhmFo69ateuONN2QYhl555RVNmjRJXq9XS5Ys0SeffKLPfvazKi4uVnZ2tk4++WS9+uqrCY/ZcUqfYRh64okn9LnPfU6ZmZkaMWKEXn755QP6WpaVlemzn/2ssrOzlZubqyuvvFK7du2K3b5q1Sp95jOfUU5OjnJzczVx4kQtX75ckrRt2zZdfPHFKigoUFZWlsaOHasFCxYc0PPbHZUrAAAA2FpLMKwx338lJc+99v7zlOnZ96/Uv/rVr7RhwwaNGzdO999/v6T2vZUk6c4779QDDzyg4cOHKz8/X9u3b9cFF1ygH/3oR/L5fHrqqad08cUXa/369Ro8eHCXz3Pffffp5z//uX7xi1/o17/+ta6++mpt27ZNhYWF+xyjaZq69NJLlZWVpcWLFysUCummm27SVVddpTfeeEOSdPXVV+vEE0/UvHnz5HQ6tXLlSrndbknSzTffrEAgoDfffFNZWVlau3atsrOz9/m8vQnhCgAAADjM8vLy5PF4lJmZqZKSkk6333///Tr33HNj1/v06aMJEybErv/oRz/Siy++qJdfflm33HJLl88zY8YMffGLX5Qk/eQnP9Gvf/1rLVu2TOeff/4+x/jqq6/qww8/1JYtW1RaWipJ+sMf/qCxY8fqvffe08knn6yysjJ961vf0qhRoyRJI0aMiN2/rKxMl19+uY4//nhJ0vDhw/f5nL0N4QoAAAC2luF2au3956XsuXvCpEmTEq43NTXpvvvu0z//+U/t3LlToVBILS0tKisr6/Zxxo8fH7uclZWlnJwcVVVV7dcY1q1bp9LS0liwkqQxY8YoPz9f69at08knn6xZs2bphhtu0B/+8Aedc845+vznP69jjjlGknTrrbfqa1/7mhYuXKhzzjlHl19+ecJ4jgasuQIAAICtGYahTI8rJR+GYfTIa+jY9e9b3/qWnn/+ef34xz/WkiVLtHLlSh1//PEKBALdPk50il781yYSiezXGEzTTPp64o/fe++9WrNmjS688EL997//1ZgxY/Tiiy9Kkm644QZt3rxZ11xzjVavXq1Jkybp17/+9X49d29BuAIAAACOAI/Ho3A4vF/nLlmyRDNmzNDnPvc5HX/88SopKYmtzzpcxowZo7KyMpWXl8eOrV27VnV1dRo9enTs2HHHHafbb79dCxcu1GWXXabf/e53sdtKS0s1c+ZMvfDCC/rmN7+pxx9//LCOOd0QrgAAAIAjYOjQofrf//6nrVu3qrq6utuK0rHHHqsXXnhBK1eu1KpVq/SlL31pvytQB+ucc87R+PHjdfXVV+uDDz7QsmXLdO211+rTn/60Jk2apJaWFt1yyy164403tG3bNr399tt67733YsHrtttu0yuvvKItW7bogw8+0H//+9+EUHY0IFylueV/uU9lP5qg5X+5P9VDAQAAwCG444475HQ6NWbMGPXt27fb9VMPPfSQCgoKNGXKFF188cU677zzdNJJJx3W8RmGoZdeekkFBQX61Kc+pXPOOUfDhw/Xs88+K0lyOp3as2ePrr32Wh133HG68sorNX36dN13332SpHA4rJtvvlmjR4/W+eefr5EjR2ru3LmHdczpxjD3tzn/UaS+vl55eXmqq6tTbm5uSsey9Ddf15SKp/W/flfq1JuOrrIqAABAMq2trdqyZYuGDRsmn8+X6uGgF+juPXUg2YDKVZoLua29ATzhphSPBAAAAEB3CFdpLuyywpU7RLgCAAAA0hnhKs2FPDmSJE+oMcUjAQAAANAdwlWai7RNC/SGm1M8EgAAAADdIVyluYinbc1VhGmBAAAAQDojXKW5SNu0wIww0wIBAACAdEa4SndeK1z5IkwLBAAAANIZ4SrNmW2VK5/ZIkXCKR4NAAAAgK4QrtKc2Va5kiQFmBoIAABwNBs6dKjmzJkTu24Yhl566aUuz9+6dasMw9DKlSsP6Xl76nH2ZcaMGbr00ksP63McTq5UDwDdc7l9CphOeYyw5G+QfHmpHhIAAADSREVFhQoKCnr0MWfMmKHa2tqE0FZaWqqKigoVFRX16HP1NoSrNOdyOdWgTPVRgxWuAAAAgDYlJSVH5HmcTucRey47Y1pgmnM7DTWaGdYVwhUAAIAt/eY3v9HAgQMViUQSjl9yySW67rrrJEmffPKJPvvZz6q4uFjZ2dk6+eST9eqrr3b7uB2nBS5btkwnnniifD6fJk2apBUrViScHw6Hdf3112vYsGHKyMjQyJEj9atf/Sp2+7333qunnnpKf//732UYhgzD0BtvvJF0WuDixYt1yimnyOv1qn///vrOd76jUCgUu/3MM8/UrbfeqjvvvFOFhYUqKSnRvffee0BfN7/fr1tvvVX9+vWTz+fTGWecoffeey92+969e3X11Verb9++ysjI0IgRI/S73/1OkhQIBHTLLbeof//+8vl8Gjp0qGbPnn1Az3+gqFylObfToUZFw1V9agcDAACQjkxTCqaos7I7UzKMfZ72+c9/Xrfeeqtef/11nX322ZKsYPDKK6/oH//4hySpsbFRF1xwgX70ox/J5/Ppqaee0sUXX6z169dr8ODB+3yOpqYmXXTRRTrrrLP0xz/+UVu2bNE3vvGNhHMikYgGDRqk5557TkVFRVq6dKm++tWvqn///rryyit1xx13aN26daqvr4+FlMLCQu3cuTPhcXbs2KELLrhAM2bM0NNPP62PP/5YN954o3w+X0KAeuqppzRr1iz973//0zvvvKMZM2bo9NNP17nnnrvP1yNJd955p55//nk99dRTGjJkiH7+85/rvPPO06ZNm1RYWKjvfe97Wrt2rf7973+rqKhImzZtUktLiyTp4Ycf1ssvv6znnntOgwcPVnl5ucrLy/freQ8W4SrNuRxGXLiicgUAANBJsFn6yYDUPPfdOyVP1j5PKyws1Pnnn68///nPsXD117/+VYWFhbHrEyZM0IQJE2L3+dGPfqQXX3xRL7/8sm655ZZ9Psef/vQnhcNhzZ8/X5mZmRo7dqy2b9+ur33ta7Fz3G637rvvvtj1YcOGaenSpXruued05ZVXKjs7WxkZGfL7/d1OA5w7d65KS0v1yCOPyDAMjRo1Sjt37tS3v/1tff/735fDYU2QGz9+vH7wgx9IkkaMGKFHHnlEr7322n6Fq6amJs2bN0+///3vNX36dEnS448/rkWLFunJJ5/Ut771LZWVlenEE0/UpEmTJFkNP6LKyso0YsQInXHGGTIMQ0OGDNnncx4qpgWmObfLoYbotMBWKlcAAAB2dfXVV+v555+X3++XZIWhL3zhC3I6nZKsMHHnnXdqzJgxys/PV3Z2tj7++GOVlZXt1+OvW7dOEyZMUGZmZuzY5MmTO5332GOPadKkSerbt6+ys7P1+OOP7/dzxD/X5MmTZcRV7U4//XQ1NjZq+/btsWPjx49PuF///v1VVVW1X8/xySefKBgM6vTTT48dc7vdOuWUU7Ru3TpJ0te+9jU988wzOuGEE3TnnXdq6dKlsXNnzJihlStXauTIkbr11lu1cOHCA3qNB4PKVZpzOxxUrgAAALrjzrQqSKl67v108cUXKxKJ6F//+pdOPvlkLVmyRA8++GDs9m9961t65ZVX9MADD+jYY49VRkaGrrjiCgUCgf16fNM093nOc889p9tvv12//OUvNXnyZOXk5OgXv/iF/ve//+3364g+l9FhOmT0+eOPu93uhHMMw+i07qy75+j4eB2fe/r06dq2bZv+9a9/6dVXX9XZZ5+tm2++WQ888IBOOukkbdmyRf/+97/16quv6sorr9Q555yjv/3tbwf0Wg8E4SrNuV00tAAAAOiWYezX1LxUy8jI0GWXXaY//elP2rRpk4477jhNnDgxdvuSJUs0Y8YMfe5zn5NkrcHaunXrfj/+mDFj9Ic//EEtLS3KyLB+f3z33XcTzlmyZImmTJmim266KXbsk08+STjH4/EoHA7v87mef/75hKCzdOlS5eTkaODAgfs95u4ce+yx8ng8euutt/SlL31JkhQMBrV8+XLddtttsfP69u2rGTNmaMaMGZo6daq+9a1v6YEHHpAk5ebm6qqrrtJVV12lK664Queff75qampUWFjYI2PsiGmBac7lcKhRbX8RIVwBAADY2tVXX61//etfmj9/vr785S8n3HbsscfqhRde0MqVK7Vq1Sp96Utf2u8qjyR96UtfksPh0PXXX6+1a9dqwYIFsZAR/xzLly/XK6+8og0bNuh73/teQvc9yVq39OGHH2r9+vWqrq5WMBjs9Fw33XSTysvL9fWvf10ff/yx/v73v+sHP/iBZs2aFVtvdaiysrL0ta99Td/61rf0n//8R2vXrtWNN96o5uZmXX/99ZKk73//+/r73/+uTZs2ac2aNfrnP/+p0aNHS5IeeughPfPMM/r444+1YcMG/fWvf1VJSYny8/N7ZHzJEK7SnNtptK+5olsgAACArZ111lkqLCzU+vXrY9WYqIceekgFBQWaMmWKLr74Yp133nk66aST9vuxs7Oz9Y9//ENr167ViSeeqHvuuUc/+9nPEs6ZOXOmLrvsMl111VU69dRTtWfPnoQqliTdeOONGjlyZGxd1ttvv93puQYOHKgFCxZo2bJlmjBhgmbOnKnrr79e3/3udw/gq7FvP/3pT3X55Zfrmmuu0UknnaRNmzbplVdeiW2c7PF4dNddd2n8+PH61Kc+JafTqWeeeSb29fjZz36mSZMm6eSTT9bWrVu1YMGCHgt/yRjm/kzOPMrU19crLy9PdXV1ys3NTelYdta26LFffFv3u5+SxlwqXflUSscDAACQaq2trdqyZYuGDRsmn8+X6uGgF+juPXUg2YDKVZpzsYkwAAAAYAuEqzQX3y3QJFwBAAAAaYtwlebcLoca2hpamKy5AgAAANIW4SrNuRxx0wLZRBgAAABIW4SrNOd2tk8LNFrrUjwaAAAAAF0hXKU5p8NQlaxWk0awSWrak+IRAQAApAeaXqOn9NR7iXBlA0FnprabRdaVPRtTOxgAAIAUczqdkqRAIJDikaC3iL6Xou+tg+XqicHg8PI4Hdoc6a9BzmqpeoM0+LRUDwkAACBlXC6XMjMztXv3brnd7sO6KSx6v0gkot27dyszM1Mu16HFI8KVDbichj4JD9CntNoKVwAAAEcxwzDUv39/bdmyRdu2bUv1cNALOBwODR48WIZhHNLjpDxczZ07V7/4xS9UUVGhsWPHas6cOZo6dWqX5y9evFizZs3SmjVrNGDAAN15552aOXNmwjlz5szRvHnzVFZWpqKiIl1xxRWaPXu2bXfwdjsd+sQcYF2p3pTawQAAAKQBj8ejESNGMDUQPcLj8fRIBTSl4erZZ5/Vbbfdprlz5+r000/Xb37zG02fPl1r167V4MGDO52/ZcsWXXDBBbrxxhv1xz/+UW+//bZuuukm9e3bV5dffrkk6U9/+pO+853vaP78+ZoyZYo2bNigGTNmSJIeeuihI/nyeozbYcSFKypXAAAAklVtsOsfz9E7GWYK26yceuqpOumkkzRv3rzYsdGjR+vSSy/V7NmzO53/7W9/Wy+//LLWrVsXOzZz5kytWrVK77zzjiTplltu0bp16/Taa6/FzvnmN7+pZcuWacmSJfs1rvr6euXl5amurk65ubkH+/J6zKd+/rpaa3Zome9myXBK91RILm+qhwUAAAD0egeSDVK2+i8QCOj999/XtGnTEo5PmzZNS5cuTXqfd955p9P55513npYvX65gMChJOuOMM/T+++9r2bJlkqTNmzdrwYIFuvDCC7sci9/vV319fcJHOnE7DVUpXyF3tmSGpZotqR4SAAAAgA5SFq6qq6sVDodVXFyccLy4uFiVlZVJ71NZWZn0/FAopOrqaknSF77wBf3whz/UGWecIbfbrWOOOUaf+cxn9J3vfKfLscyePVt5eXmxj9LS0kN8dT3L7XRIMtSSO9w6wNRAAAAAIO2kvG9lx44cpml226Uj2fnxx9944w39+Mc/1ty5c/XBBx/ohRde0D//+U/98Ic/7PIx77rrLtXV1cU+ysvLD/blHBZWuJICXmszYfnTq7IGAAAAIIUNLYqKiuR0OjtVqaqqqjpVp6JKSkqSnu9yudSnTx9J0ve+9z1dc801uuGGGyRJxx9/vJqamvTVr35V99xzT9IuIF6vV15v+q5hcjmt4BhW26ZmkVAKRwMAAAAgmZRVrjwejyZOnKhFixYlHF+0aJGmTJmS9D6TJ0/udP7ChQs1adIkud1uSVJzc3OnAOV0OmWaplLYu+OQuNteT4RwBQAAAKStlE4LnDVrlp544gnNnz9f69at0+23366ysrLYvlV33XWXrr322tj5M2fO1LZt2zRr1iytW7dO8+fP15NPPqk77rgjds7FF1+sefPm6ZlnntGWLVu0aNEife9739Mll1wip9N5xF9jT3C72ipXRjRcRVI4GgAAAADJpHSfq6uuukp79uzR/fffr4qKCo0bN04LFizQkCFDJEkVFRUqKyuLnT9s2DAtWLBAt99+ux599FENGDBADz/8cGyPK0n67ne/K8Mw9N3vflc7duxQ3759dfHFF+vHP/7xEX99PcXVVrliWiAAAACQvlK6z1W6Srd9rm54arleXbdLrx/zFw3b8Q/p3B9Kp9+a6mEBAAAAvZ4t9rnC/nPHGlq0fbuoXAEAAABph3BlAy5nx2mB4RSOBgAAAEAyhCsbiFauQmZbuDIJVwAAAEC6IVzZQLQVe9hgWiAAAACQrghXNuDqWLkiXAEAAABph3BlA+62NVch0wpZhCsAAAAg/RCubCC25oqGFgAAAEDaIlzZQHvlijVXAAAAQLoiXNlAtBU7lSsAAAAgfRGubMDtsKYFBqlcAQAAAGmLcGUDblfHhhZUrgAAAIB0Q7iyAReVKwAAACDtEa5swNNWuSJcAQAAAOmLcGUDLkc0XLU1tDCZFggAAACkG8KVDbic0WmBbCIMAAAApCvClQ14nB0qVzS0AAAAANIO4coGYpWrCJUrAAAAIF0RrmzA7aShBQAAAJDuCFc24G6rXAXY5woAAABIW4QrG4h2C/RHWHMFAAAApCvClQ1EpwUGWHMFAAAApC3ClQ24aWgBAAAApD3ClQ20V65oaAEAAACkK8KVDURbsfsjNLQAAAAA0hXhygZilatoK3aTcAUAAACkG8KVDUTDlT/MmisAAAAgXRGubCDa0KKVcAUAAACkLcKVDfjc1v5WhCsAAAAgfRGubCAarkLRbxcNLQAAAIC0Q7iyAZ/L+jaFZYUswhUAAACQfghXNuByOuR2GgrFwhXTAgEAAIB0Q7iyCZ/LqbDYRBgAAABIV4Qrm/B54sMV0wIBAACAdEO4sgmf2xG35orKFQAAAJBuCFc24XM5FTKZFggAAACkK8KVTfjczvbKlcm0QAAAACDdEK5sIsPtbN/nyoxIkUhqBwQAAAAgAeHKJrzxa64kqlcAAABAmiFc2YQ1LTDu28W6KwAAACCtEK5swpoWGFe5IlwBAAAAaYVwZRNWK/b4yhXTAgEAAIB0Qriyic7TAglXAAAAQDohXNlEhtspUw5FxF5XAAAAQDoiXNmE122tt4oYhCsAAAAgHRGubMLntr5VkWhTC8IVAAAAkFYIVzaR0Va5ChuEKwAAACAdEa5swhedFhitXJmRFI4GAAAAQEeEK5uITgsM09ACAAAASEuEK5uITgsMseYKAAAASEuEK5uIdgukcgUAAACkJ8KVTfhcbZUrMxqu2EQYAAAASCeEK5uIrrlqnxZIuAIAAADSCeHKJjI8HStXTAsEAAAA0gnhyiai0wKDhCsAAAAgLRGubCK6zxWVKwAAACA9Ea5sor0VOw0tAAAAgHREuLIJb2wT4baGFibhCgAAAEgnhCub8LocMoz4yhXTAgEAAIB0QriyCcMw5HM52ytXhCsAAAAgrRCubMTndrCJMAAAAJCmCFc24nM7FWFaIAAAAJCWCFc2kuF2KsS0QAAAACAtEa5sxOuOX3PFtEAAAAAgnRCubMTndtAtEAAAAEhThCsbSewWSOUKAAAASCeEKxvxuh0KU7kCAAAA0hLhykZcDqYFAgAAAOmKcGUjHpehsNk2LdBkWiAAAACQTghXNkLlCgAAAEhfhCsbcTkNGloAAAAAaYpwZSNuh4NNhAEAAIA0RbiyEZfTUIRpgQAAAEBaIlzZiNvJmisAAAAgXRGubMTliF9zFUntYAAAAAAkIFzZiIvKFQAAAJC2CFc24nbG7XNFuAIAAADSCuHKRlwOh8JUrgAAAIC0RLiyEfa5AgAAANIX4cpG3E6jfc2VSbgCAAAA0gnhykasaYGsuQIAAADSEeHKRhIqV4QrAAAAIK2kPFzNnTtXw4YNk8/n08SJE7VkyZJuz1+8eLEmTpwon8+n4cOH67HHHku4/cwzz5RhGJ0+LrzwwsP5Mo4Il5PKFQAAAJCuUhqunn32Wd1222265557tGLFCk2dOlXTp09XWVlZ0vO3bNmiCy64QFOnTtWKFSt0991369Zbb9Xzzz8fO+eFF15QRUVF7OOjjz6S0+nU5z//+SP1sg4baxPhaOWKNVcAAABAOklpuHrwwQd1/fXX64YbbtDo0aM1Z84clZaWat68eUnPf+yxxzR48GDNmTNHo0eP1g033KCvfOUreuCBB2LnFBYWqqSkJPaxaNEiZWZm9opw5XbSih0AAABIVykLV4FAQO+//76mTZuWcHzatGlaunRp0vu88847nc4/77zztHz5cgWDwaT3efLJJ/WFL3xBWVlZXY7F7/ervr4+4SMduZyGQiat2AEAAIB0lLJwVV1drXA4rOLi4oTjxcXFqqysTHqfysrKpOeHQiFVV1d3On/ZsmX66KOPdMMNN3Q7ltmzZysvLy/2UVpaeoCv5sigWyAAAACQvlLe0MIwjITrpml2Orav85Mdl6yq1bhx43TKKad0O4a77rpLdXV1sY/y8vL9Hf4RldgtkMoVAAAAkE5cqXrioqIiOZ3OTlWqqqqqTtWpqJKSkqTnu1wu9enTJ+F4c3OznnnmGd1///37HIvX65XX6z3AV3Dk0S0QAAAASF8pq1x5PB5NnDhRixYtSji+aNEiTZkyJel9Jk+e3On8hQsXatKkSXK73QnHn3vuOfn9fn35y1/u2YGnkNtp0NACAAAASFMpnRY4a9YsPfHEE5o/f77WrVun22+/XWVlZZo5c6Yka7retddeGzt/5syZ2rZtm2bNmqV169Zp/vz5evLJJ3XHHXd0euwnn3xSl156aaeKlp0ldAs0I6kdDAAAAIAEKZsWKElXXXWV9uzZo/vvv18VFRUaN26cFixYoCFDhkiSKioqEva8GjZsmBYsWKDbb79djz76qAYMGKCHH35Yl19+ecLjbtiwQW+99ZYWLlx4RF/P4eZyGDLVtraMcAUAAACkFcOMdoRATH19vfLy8lRXV6fc3NxUDyfmox11+vmjj+ppz8+kkvHSzCWpHhIAAADQqx1INkh5t0DsP5fTUIRpgQAAAEBaIlzZiMvhUIRpgQAAAEBaIlzZiJvKFQAAAJC2CFc24nI6FDGpXAEAAADpiHBlI26HwbRAAAAAIE0RrmzE5XTEpgWakXCKRwMAAAAgHuHKRugWCAAAAKQvwpWNuOO6BZqEKwAAACCtEK5sxKpcta25ihCuAAAAgHRCuLIRl8OQGV1zZbLmCgAAAEgnhCsbMQxDhqPtW0blCgAAAEgrhCubMRxO6wJrrgAAAIC0QriyGQfhCgAAAEhLhCubcThoxQ4AAACkI8KVzTicVK4AAACAdES4shmmBQIAAADpiXBlM4QrAAAAID0RrmzG4WTNFQAAAJCOCFc242xbc2UQrgAAAIC0QriyGSfdAgEAAIC0RLiyGcPpsj6LcAUAAACkE8KVzTgdTAsEAAAA0hHhymai4UqSFCFgAQAAAOmCcGUzsW6BEuuuAAAAgDRCuLIZp8vVfoVwBQAAAKQNwpXNOOKnBRKuAAAAgLRBuLIZl5NwBQAAAKQjwpXNOBPCVTh1AwEAAACQgHBlM0wLBAAAANIT4cpmXC7CFQAAAJCOCFc2kzgt0EzdQAAAAAAkIFzZTOImwqy5AgAAANIF4cpm3C6HIqZhXWFaIAAAAJA2CFc243I6FI5+2whXAAAAQNogXNmM22EoIipXAAAAQLohXNmMy+mQSbgCAAAA0g7hymZcTkOR2LRAGloAAAAA6YJwZTNuh4NpgQAAAEAaIlzZTGLlin2uAAAAgHRBuLIZt5PKFQAAAJCOCFc243bGdQtkE2EAAAAgbRCubMblcMRNC6RyBQAAAKQLwpXNJK65IlwBAAAA6YJwZTOsuQIAAADSE+HKZlyOuDVX7HMFAAAApA3Clc0wLRAAAABIT4Qrm3E6HDLNaOWKfa4AAACAdEG4shmXw1CYyhUAAACQdghXNuNMWHNFuAIAAADSBeHKZpwOQyabCAMAAABph3BlM1blimmBAAAAQLohXNkMa64AAACA9ES4spmEaYGEKwAAACBtEK5sxuVwsIkwAAAAkIYIVzbjdCguXLHPFQAAAJAuCFc243Q4aGgBAAAApCHClc246BYIAAAApCXClc2wiTAAAACQnghXNuOKD1dsIgwAAACkDcKVzTjipgWaVK4AAACAtEG4shlX3D5XkTCVKwAAACBdEK5sxukwFDatb1uEfa4AAACAtEG4spn4TYSpXAEAAADpg3BlM874aYER1lwBAAAA6YJwZTPOuIYWVK4AAACA9EG4shmHIYXbvm1hKlcAAABA2iBc2YxhGJIR3ecqlNrBAAAAAIghXNmQSeUKAAAASDuEKxsy2ypXJmuuAAAAgLRBuLIh02hraBEhXAEAAADpgnBlQ9FpgbRiBwAAANIH4cqO2ipXJpUrAAAAIG0QruzIoHIFAAAApBvClQ1FpwVSuQIAAADSB+HKhkwqVwAAAEDaIVzZEWuuAAAAgLRDuLIjwhUAAACQdghXNmTGwhXTAgEAAIB0QbiyIcMwJEkRk8oVAAAAkC4IVzZkGk7rM5UrAAAAIG0QruyINVcAAABA2kl5uJo7d66GDRsmn8+niRMnasmSJd2ev3jxYk2cOFE+n0/Dhw/XY4891umc2tpa3Xzzzerfv798Pp9Gjx6tBQsWHK6XcOSx5goAAABIOykNV88++6xuu+023XPPPVqxYoWmTp2q6dOnq6ysLOn5W7Zs0QUXXKCpU6dqxYoVuvvuu3Xrrbfq+eefj50TCAR07rnnauvWrfrb3/6m9evX6/HHH9fAgQOP1Ms6/KLhyiRcAQAAAOnClconf/DBB3X99dfrhhtukCTNmTNHr7zyiubNm6fZs2d3Ov+xxx7T4MGDNWfOHEnS6NGjtXz5cj3wwAO6/PLLJUnz589XTU2Nli5dKrfbLUkaMmTIkXlBR4qDNVcAAABAuklZ5SoQCOj999/XtGnTEo5PmzZNS5cuTXqfd955p9P55513npYvX65gMChJevnllzV58mTdfPPNKi4u1rhx4/STn/xE4XDX65P8fr/q6+sTPtKZGf22seYKAAAASBspC1fV1dUKh8MqLi5OOF5cXKzKysqk96msrEx6figUUnV1tSRp8+bN+tvf/qZwOKwFCxbou9/9rn75y1/qxz/+cZdjmT17tvLy8mIfpaWlh/jqDq9oK3aTVuwAAABA2kh5Q4toUIgyTbPTsX2dH388EomoX79++u1vf6uJEyfqC1/4gu655x7Nmzevy8e86667VFdXF/soLy8/2JdzZDiiDS3MFA8EAAAAQFTK1lwVFRXJ6XR2qlJVVVV1qk5FlZSUJD3f5XKpT58+kqT+/fvL7XbL6XTGzhk9erQqKysVCATk8Xg6Pa7X65XX6z3Ul3TEGG0NLUTlCgAAAEgbKatceTweTZw4UYsWLUo4vmjRIk2ZMiXpfSZPntzp/IULF2rSpEmx5hWnn366Nm3apEhcs4cNGzaof//+SYOVLTmsTMw+VwAAAED6SOm0wFmzZumJJ57Q/PnztW7dOt1+++0qKyvTzJkzJVnT9a699trY+TNnztS2bds0a9YsrVu3TvPnz9eTTz6pO+64I3bO1772Ne3Zs0ff+MY3tGHDBv3rX//ST37yE918881H/PUdNtGpkbRiBwAAANJGSluxX3XVVdqzZ4/uv/9+VVRUaNy4cVqwYEGsdXpFRUXCnlfDhg3TggULdPvtt+vRRx/VgAED9PDDD8fasEtSaWmpFi5cqNtvv13jx4/XwIED9Y1vfEPf/va3j/jrO2yMtlbshCsAAAAgbRhmtCMEYurr65WXl6e6ujrl5uamejid/GfuHTq/6nGtKblUY2c+lerhAAAAAL3WgWSDlHcLxEFwRBtaULkCAAAA0gXhyoYcjrZOiHQLBAAAANIG4cqOoq3YI2Fp1xopHErteAAAAAAQruwous/V2Or/SPOmSG89mOIRAQAAACBc2ZDh6PBtq92WmoEAAAAAiCFc2VF0zVVUhMYWAAAAQKoRrmyoU+WKxhYAAABAyhGubMgwOlauCFcAAABAqhGubMhB5QoAAABIOwcVrsrLy7V9+/bY9WXLlum2227Tb3/72x4bGLrRac0V4QoAAABItYMKV1/60pf0+uuvS5IqKyt17rnnatmyZbr77rt1//339+gA0VnnyhUNLQAAAIBUO6hw9dFHH+mUU06RJD333HMaN26cli5dqj//+c/6/e9/35PjQxKdGlpQuQIAAABS7qDCVTAYlNfrlSS9+uqruuSSSyRJo0aNUkVFRc+NDkl1amjBmisAAAAg5Q4qXI0dO1aPPfaYlixZokWLFun888+XJO3cuVN9+vTp0QGiMypXAAAAQPo5qHD1s5/9TL/5zW905pln6otf/KImTJggSXr55Zdj0wVx+Dg6NrSgcgUAAACknOtg7nTmmWequrpa9fX1KigoiB3/6le/qszMzB4bHJIz6BYIAAAApJ2Dqly1tLTI7/fHgtW2bds0Z84crV+/Xv369evRAaIzugUCAAAA6eegwtVnP/tZPf3005Kk2tpanXrqqfrlL3+pSy+9VPPmzevRAaIzKlcAAABA+jmocPXBBx9o6tSpkqS//e1vKi4u1rZt2/T000/r4Ycf7tEBojPWXAEAAADp56DCVXNzs3JyciRJCxcu1GWXXSaHw6HTTjtN27Zt69EBojPDSbdAAAAAIN0cVLg69thj9dJLL6m8vFyvvPKKpk2bJkmqqqpSbm5ujw4QnVG5AgAAANLPQYWr73//+7rjjjs0dOhQnXLKKZo8ebIkq4p14okn9ugA0VmnhhYRGloAAAAAqXZQrdivuOIKnXHGGaqoqIjtcSVJZ599tj73uc/12OCQXOdugVSuAAAAgFQ7qHAlSSUlJSopKdH27dtlGIYGDhzIBsJHiOHo8G1jzRUAAACQcgc1LTASiej+++9XXl6ehgwZosGDBys/P18//OEPFWGK2mHndLLmCgAAAEg3B1W5uueee/Tkk0/qpz/9qU4//XSZpqm3335b9957r1pbW/XjH/+4p8eJOEanNVeEKwAAACDVDipcPfXUU3riiSd0ySWXxI5NmDBBAwcO1E033US4OsycdAsEAAAA0s5BTQusqanRqFGjOh0fNWqUampqDnlQ6J6j47RApmICAAAAKXdQ4WrChAl65JFHOh1/5JFHNH78+EMeFLrHPlcAAABA+jmoaYE///nPdeGFF+rVV1/V5MmTZRiGli5dqvLyci1YsKCnx4gOnKy5AgAAANLOQVWuPv3pT2vDhg363Oc+p9raWtXU1Oiyyy7TmjVr9Lvf/a6nx4gOOk0LNJkWCAAAAKSaYZqm2VMPtmrVKp100kkKh+1dSamvr1deXp7q6uqUm5ub6uF0Url2qUqem95+IKNA+vbWlI0HAAAA6K0OJBscVOUKqWXQ0AIAAABIO4QrG3I6OyyVo6EFAAAAkHKEKxty0NACAAAASDsH1C3wsssu6/b22traQxkL9pOzU0MLwhUAAACQagcUrvLy8vZ5+7XXXntIA8K+OV0dvm1UrgAAAICUO6BwRZv19OAwOkwLpHIFAAAApBxrrmyo07RAiY6BAAAAQIoRrmwoabiiegUAAACkFOHKhpzOJN821l0BAAAAKUW4siHDkWSpHJUrAAAAIKUIV3bUsaGFROUKAAAASDHClR0lC1dUrgAAAICUIlzZUdLKFd0CAQAAgFQiXNmRQbdAAAAAIN0QruzIMDofY80VAAAAkFKEKztizRUAAACQdghXdkS3QAAAACDtEK7siMoVAAAAkHYIV3bkSNLQgm6BAAAAQEoRruyIyhUAAACQdghXdsSaKwAAACDtEK7siMoVAAAAkHYIV3ZE5QoAAABIO4QrO0q2iTCVKwAAACClCFe9Bd0CAQAAgJQiXPUWVK4AAACAlCJc9RasuQIAAABSinDVW1C5AgAAAFKKcNVbULkCAAAAUopw1VtQuQIAAABSinDVW9AtEAAAAEgpwlVv0ZsqV28+ID12htRal+qRAAAAAPuNcNVb9KY1V6v/JlWulnauSPVIAAAAgP1GuOotelPlKhJq+9yLXhMAAAB6PcJVb9Gbgkg0KJqsIwMAAIB9EK5sanXemdprZqsqa6R1oDcFkehr6U2vCQAAAL0e4cqmnh36Q53sn6sWV551oDcFkWjnw95UjQMAAECvR7iyKZfTqZBcihht38LeFERi0wJ70WsCAABAr0e4simnw5AkRaLfwt4UREwqVwAAALAfwpVNudrCVVi9sHIVoXIFAAAA+yFc2ZSjV1eu2l5LpBetIwMAAECvR7iyqaOjckW4AgAAgH0Qrmyq85qrXhRETLPtcy8KjAAAAOj1CFc21asrV7Fpgb3oNQEAAKDXI1zZlNNhfesiphWyelWVh4YWAAAAsCHClU05275zVK4AAACA9EC4sqlo5Sps9sZugZHEzwAAAIANEK5sqvOaq14UROgWCAAAABsiXNmUs2O46i2VK9OU1NYtkGmBAAAAsJGUh6u5c+dq2LBh8vl8mjhxopYsWdLt+YsXL9bEiRPl8/k0fPhwPfbYYwm3//73v5dhGJ0+WltbD+fLOOKilatQtKFFbwki8a+jtwRGAAAAHBVSGq6effZZ3Xbbbbrnnnu0YsUKTZ06VdOnT1dZWVnS87ds2aILLrhAU6dO1YoVK3T33Xfr1ltv1fPPP59wXm5urioqKhI+fD7fkXhJR4yj11au4qYC9pbACAAAgKOCK5VP/uCDD+r666/XDTfcIEmaM2eOXnnlFc2bN0+zZ8/udP5jjz2mwYMHa86cOZKk0aNHa/ny5XrggQd0+eWXx84zDEMlJSVH5DWkSmzNVW+rXMWHRNZcAQAAwEZSVrkKBAJ6//33NW3atITj06ZN09KlS5Pe55133ul0/nnnnafly5crGAzGjjU2NmrIkCEaNGiQLrroIq1YsaLbsfj9ftXX1yd8pLteu+aKaYEAAACwqZSFq+rqaoXDYRUXFyccLy4uVmVlZdL7VFZWJj0/FAqpurpakjRq1Cj9/ve/18svv6y//OUv8vl8Ov3007Vx48YuxzJ79mzl5eXFPkpLSw/x1R1+rrZW7CGzl3ULjA9UveU1AQAA4KiQ8oYWhmEkXDdNs9OxfZ0ff/y0007Tl7/8ZU2YMEFTp07Vc889p+OOO06//vWvu3zMu+66S3V1dbGP8vLyg305R0ysctXb9rmKnwrYW14TAAAAjgopW3NVVFQkp9PZqUpVVVXVqToVVVJSkvR8l8ulPn36JL2Pw+HQySef3G3lyuv1yuv1HuArSK1ouAqpl625itDQAgAAAPaUssqVx+PRxIkTtWjRooTjixYt0pQpU5LeZ/LkyZ3OX7hwoSZNmiS32530PqZpauXKlerfv3/PDDxNtLdi722VKxpaAAAAwJ5SOi1w1qxZeuKJJzR//nytW7dOt99+u8rKyjRz5kxJ1nS9a6+9Nnb+zJkztW3bNs2aNUvr1q3T/Pnz9eSTT+qOO+6InXPffffplVde0ebNm7Vy5Updf/31WrlyZewxewtnb+0WSEMLAAAA2FRKW7FfddVV2rNnj+6//35VVFRo3LhxWrBggYYMGSJJqqioSNjzatiwYVqwYIFuv/12PfrooxowYIAefvjhhDbstbW1+upXv6rKykrl5eXpxBNP1JtvvqlTTjnliL++w6n3Vq6YFggAAAB7Smm4kqSbbrpJN910U9Lbfv/733c69ulPf1offPBBl4/30EMP6aGHHuqp4aWt2JqrWOWql0yhY1ogAAAAbCrl3QJxcNobWvSyylV8tYrKFQAAAGyEcGVT0XAV7G1rrmjFDgAAAJsiXNlUdBPhcKSXVa4SwhXTAgEAAGAfhCub6rWVK6YFAgAAwKYIVzblcnZoaNFbqjwmrdgBAABgT4Qrm3IY0cpV27ewt1R5EipXvSQwAgAA4KhAuLIpV8dW7L2lykNDCwAAANgU4cqm2tdc9bLKFftcAQAAwKYIVzYVW3MV6WWVq/ipgL0lMAIAAOCoQLiyqV7bLZCGFgAAALApwpVNOY3omqvoPle9ZAqdSeUKAAAA9kS4sqnYJsLqZeEqwporAAAA2BPhyqacbWuuIurN0wIJVwAAALAPwpVNRVuxR2KVq14SrhL2ueolrwkAAABHBcKVTUUbWsSmBfaWIGKacZd7yWsCAADAUYFwZVPRhha9rnJlUrkCAACAPRGubMrhMGQY8ZWrXrI+iYYWAAAAsCnClY25HEZct8BeUuWhoQUAAABsinBlY06HoYjZ29Zcsc8VAAAA7IlwZWMuh0PhaCv23lK5SpgW2EteEwAAAI4KhCsbcxhxDS16S5WHyhUAAABsinBlYy6nI27NVS9Zn0TlCgAAADZFuLIxZ3xDi95S5YkPib0lMAIAAOCoQLiyMZfD6OX7XBGuAAAAYB+EKxvrlZUrpgUCAADApghXNubs7ftc9ZbACAAAgKMC4crGnPHTAnvLFLqENVeEKwAAANgH4crGXL2xchWhFTsAAADsiXBlY06Ho/etuYoPiaaZunEAAAAAB4hwZWMuh6GI2csqV0wLBAAAgE0RrmzM0du7BfaW1wQAAICjAuHKxnr9Ple95TUBAADgqEC4srGEVuxS7+gYSOUKAAAANkW4sjFXp3AVSt1gekp8EwuzF4RFAAAAHDUIVzbmdBgKytV+IBJM3WB6SsK0QMIVAAAA7INwZWNOh6FAfLgK+VM3mJ7CtEAAAADYFOHKxlwOQyE5ZcqwDoQDqR1QT6ChBQAAAGyKcGVjTochyVDY4bEO9IbKVfxUQCpXAAAAsBHClY25HNa3LxINV72hchVhzRUAAADsiXBlY1blSgo73NaB3la5YlogAAAAbIRwZWOxcGW0haveVrmSesfeXQAAADgqEK5srFeGq45TAaleAQAAwCYIVzbmik0L7E0NLTpWrghXAAAAsAfClY1FK1eh3lS56himaGoBAAAAmyBc2ZirY7jqjZUrpgUCAADAJghXNuaIhate1Iq9Y6WKaYEAAACwCcKVjcXWXBku60BvCFcduwMyLRAAAAA2QbiyMWfbJsLB3jwtkMoVAAAAbIJwZWOd1lz1isoVDS0AAABgT4QrG4t2C+xdlSv2uQIAAIA9Ea5sLBau1IsqV0wLBAAAgE0RrmzM47K+fX71poYWtGIHAACAPRGubCzL45Qk+SNt4ao3TgukcgUAAACbIFzZWIbHClUtkUOoXDVUSq/Plup3dr7NNKXqjVI4dAijPECd1lzR0AIAAAD2QLiyscy2ylVLxPp8UJWr5fOlxT+V3nui820fPis9Mkn6952HMMoDRLdAAAAA2BThysYy2sJVczRcHUzlqrUu8XO8xT+zPi9/8iBGd5BoaAEAAACbIlzZWFZ0WmD4EMJVtNqVrOpVNLL9smke+GMfDBpaAAAAwKYIVzYWnRbYFD6EhhbRQJYsmBUMab9cW9bF/YNSsPXAn7crNLQAAACATRGubCwjFq6s/a56vHIVX63a9VHy23/7GemRk62Q1RPYRBgAAAA2RbiysWjlqjF0CA0twm33SRbM4o9VJglX4aC0a7VUVyY11xz4cyfTaVrgEZqOCAAAABwiwpWNZfZEK/ZQ232SBbOEcPVh97eHe2iPLRpaAAAAwKYIVzYWrVwF5LYOHEy46m7NVfyxZNMCE8LVPqYFrnpG2vTqvsfDtEAAAADYFOHKxtxOh9xOQwH1QEOLZPeNP7Z3a3uA+uS/0qv3ScGW5Od2tHeb9OL/k/54uRTZx75VHStVVK4AAABgE65UDwCHJsPtVCBwCJWrUHdrrjpUo0KtktMtLfq+VLla6jsq7txuwpW/of1yY6WUO6DrcztWqqhcAQAAwCaoXNlclteloHkolavuwlWHx4uuz2pp23C4Ja6JRXfTAuMfe+/W7sfTsbLVcZogAAAAkKYIVzaX4XG2Tws8mKYS3Ta06BCYoo8fbLY+x1ekugt20fOlfYerTvtcEa4AAABgD4Qrm8v0OOMaWhzEXlPdVa46Bqbo9ehaq0Bj58dJJn5t1t5t3Y+HaYEAAACwKcKVzWW6XfIfSkOL/W3FHr1umnGVq/hw1U2wCzS1X45Wrja8Ii3+Red9rGhoAQAAAJuioYXNZXqdquyRVuz7Ea5CfquphdoC0X5PC4yvXG21Pv/7TuvyqAuk4rHtt8cqVYb1PFSuAAAAYBNUrmwu0+NU4JAaWkQrV/vY5yp6PT4oJUwL7CbYBZNUrqLBLD6gSe1rrpzuxOsAAABAmiNc2VyG26VgtAAZCR54A4hYK/Zk+1wlqVzFT/GLD0bdhqu4QNZYKQWa25831Jp4bnT8jrZwxbRAAAAA2AThyuYSGlpIVsDaX6bZHqrMiBQOJd7eqXLl77py1V3VLNCceL22LC5cdbhfdBoglSsAAADYDOHK5jK9ca3YpQObGthVq/WO1z05bY8dSJzit78NLYIdwlXN5vYQ2KlyFQ1XnsTrAAAAQJojXNlcptuVGK4OpKlFp02CO4artgDkzW4/v8s1V/u5z5Uk1W2Pe84O4+205opwBQAAAHsgXNlcpscpUw6FDqYde8dgk6w7oCR54ytXcUEpoVtgd2uuOoSr1rq4+3WoXDEtEAAAADZFuLK5DI9TkhQy2sJV2C9tXCQt/F7nNVQddRWmJGs9VnTqnieuchW/fmq/uwW2JF5vrY17zi4aWvTEtMDWOumdR6W6HQf/GAAAAMB+IlzZXJbXCldBI7rXVVB65W5p6cNS2dLu79xpjVUg+eVY5crfOSh19VjxYoHMsD4lVK66aGjh6IFpgauesb4Wb//q4B8DAAAA2E+EK5vLcFsVq2C0Y2DIb3Xjk6SGXd3fOVmr9ahk4Soc6DzFr6vHihe9T2ah9Tk+XHUMZbE1V9H28ocQrpr3JH4GAAAADiPClc1ltk0LjLVjb6hsn2rXXN39nbvqDiglhqXotMCQv+tw1e20wLb7ZBRYn7urXHXsFngoa6662ksLAAAAOAxc+z4F6Swarvxm27dy75b2G5t2d3/nTpWrJNMCHS7J7Wu73d/1Plrddgtsm0qYkaRy1WVDix5YcxUNV11NZQQAAAB6EOHK5jI91rcwFq5q4sPVQVauqtZZDS0kK+S4fO23d5V1upsWGGjbGys6LdBfH3e/ripXPdAtMBrcDqSDIgAAAHCQUj4tcO7cuRo2bJh8Pp8mTpyoJUuWdHv+4sWLNXHiRPl8Pg0fPlyPPfZYl+c+88wzMgxDl156aQ+POn3EpgXGKldb22/cZ7hKUrmqWCXNPU3621esY05PexUp1KFbYHePFW9/K1emKakt1PVEQ4vomEJUrgAAAHD4pTRcPfvss7rtttt0zz33aMWKFZo6daqmT5+usrKypOdv2bJFF1xwgaZOnaoVK1bo7rvv1q233qrnn3++07nbtm3THXfcoalTpx7ul5FS0XDValqfE6YF7mvNVad9rvxS1cfW5d1tn50eyeVtu72bhhb7s+YqWUOL+DHEV6milatDmhbYFtyCrLkCAADA4ZfScPXggw/q+uuv1w033KDRo0drzpw5Ki0t1bx585Ke/9hjj2nw4MGaM2eORo8erRtuuEFf+cpX9MADDyScFw6HdfXVV+u+++7T8OHDj8RLSZncDCuE+M22MHIo0wJDfqllb9uVtgqSyys5ve23d9ktsLs1V9GGFvnW50jc/lvxlav4IOXsgcpVrKEFlSsAAAAcfikLV4FAQO+//76mTZuWcHzatGlaujT5/kzvvPNOp/PPO+88LV++XMFge6OF+++/X3379tX111+/X2Px+/2qr69P+LALn9upfjleBRS3iXDUvsJVx0AUDsSFqzZOt+TytN/e5T5XXVSuQoH2MBWdFtjVGOIrV9FpgZGe6BbImisAAAAcfikLV9XV1QqHwyouLk44XlxcrMrKyqT3qaysTHp+KBRSdbUVJN5++209+eSTevzxx/d7LLNnz1ZeXl7so7S09ABfTWoN6ZPZ3oo9nr8ucdpdxSqpfmf79U5rrvxJwtV+Vq66Clfx52cmC1fxa67iK1c90Yo9Oi2QyhUAAAAOv5Q3tDAMI+G6aZqdju3r/OjxhoYGffnLX9bjjz+uoqKi/R7DXXfdpbq6uthHeXn5AbyC1CstzFSjfMlvjK67qtsh/fZM6Y9XtN92MJWrrhpadFUdioYrw9m+GXHH54w6bNMCWXMFAACAwy9lrdiLiorkdDo7Vamqqqo6VaeiSkpKkp7vcrnUp08frVmzRlu3btXFF18cuz3SNq3M5XJp/fr1OuaYYzo9rtfrldfrPdSXlDKDCzP1j/AUXe58q/2gN8+qXDVVS7kDpJrNVhWoaq0VOlze/atc7e+aq3AX+19Fq0aeLMmV0fn2fVWuDqWhRThunyvTlLoJ7QAAAMChSlnlyuPxaOLEiVq0aFHC8UWLFmnKlClJ7zN58uRO5y9cuFCTJk2S2+3WqFGjtHr1aq1cuTL2cckll+gzn/mMVq5cabvpfvtrSJ9MvRGZoAYjrjKUN9D6HN1IuKWm7QZTqm3rxtgxXIX9cee1SegW6O9mzVUXlavoHlfujPb9suJ1asUefd4erFzJ7L6bIQAAANADUrqJ8KxZs3TNNddo0qRJmjx5sn7729+qrKxMM2fOlGRN19uxY4eefvppSdLMmTP1yCOPaNasWbrxxhv1zjvv6Mknn9Rf/vIXSZLP59O4ceMSniM/P1+SOh3vTQYXZkoy9C33XXos9APpmLPaO+Q170n8LFl7YRWN6DyVL5RsWmD8PlfdtGLvahPhaBhzZ7aHtIT7xY0hvkrlcHY+dqDig1uoNfnzAwAAAD0kpeHqqquu0p49e3T//feroqJC48aN04IFCzRkyBBJUkVFRcKeV8OGDdOCBQt0++2369FHH9WAAQP08MMP6/LLL0/VS0gLpYWZkqRXGoYq8K2V8mQXSn+/2box2jGwY7iSuqhcJQlXCZWrg2xo4c60qlcdJXQLbAtShsNaoyUlVrMOVHzgC7ZKvryDfywAAABgH1IariTppptu0k033ZT0tt///vedjn3605/WBx98sN+Pn+wxepu+2V5luJ1qCYa1PZyv4Z5MKauvdWN0WmBzXGiK7oXVsXIVbJVaahOPuTpWrg5wWmA0XHkOoHJlONsrV4c0LTC+ckXHQAAAABxeKe8WiENnGEbb1ECprKYtzGS1dUtsPoDKVdNuxTYPjoqvXIVauu68t89pgfuz5qqt7brD2V65OqRpgXHBLUjHQAAAABxehKteIjo1cGt1WwOJ3LaGFrs3WJ/jG1Xs7VC5inYDbNzV+YHj97nqWNWK19W0wFhDi8wuwlUX0wJ7onIVX02jHTsAAAAOM8JVLzGqxOoUuLai3jow9HTr847lkr+xc+XKNNvDR3T/qYaKzg8cv89Va23cDR3amkeCUiTJhr8JDS2ShKuwv31dVfy0QMOReOxAhUNSJNR+nXAFAACAw4xw1UuMG2g1a1i9oy1cFQyV8odYAWPb0sRwFWy2pgBG96aKhasklav4fa6i0/ZcGcnXT0WS7HUVjKtcOV3t0/2izEh7CIpNC3S0hyszSWDbHx3XgHW1VgwAAADoIYSrXmLcwFxJ0sZdDWoNtlV7hn3K+rxlcXtDi2hoqdnSPiXPm219jgaheE5Pe+UqypPZHrjidWyQIcVtImxNW0zeMbCtqhQNUgkNLQ4yXHVqM0/lCgAAAIcX4aqXGJifoYJMt0IRU+srG6yDw8+0Pm96TfLXWZeLx1qfd69rXyflze36gZ2ezkHKndk5cEnJ1135G63Pnizrc3cdAyNJWrF3Ny3Q3yg17k5+W6dOiFSuAAAAcHgRrnoJwzDipga2Balo5Wr3uuhZ0vDPWBd3roirXOV0/cDx3QKjPFnJK1fhgDXVsG5H+7HWtrFE95hydbPXVbR5hWM/W7HPP196+IT250h4zA6VqmRVNQAAAKAHEa56kePbwtVH0XCV3U/qc2z7CRn50qBJ1uUdH8RVrjqEK3dW++X4fa6isvomr1yF/NbmxQ+NkSo+tI51ClfJKldtQSihocU+KleBJmnXainQKO3d1vn2jlW06D5XzTXta80AAACAHkS46kWilaslG6vVHGhrEjFwUvsJmX2kASdal6vWtgefjuEqv7T9crLKVXa/xMpVNHyFA9KO963LFausz/62BhuxcNVNO/bYmqv4hhZdhKva8vbL+1O5CrZKddulX46Unr0m+WNKVufCQHPXtwMAAABdIFz1ImeMKFK/HK921Lbouy99JNM02ytVkpRRKOWVSplFVoe+yrbqUqdwNbj9stMrOVztYUeSsoutFu1RnraGGCG/VL/TutzUthYq2r7d2xau3N1sJBzfLTDaAKOroFMbV61KGq46NrRokXautAJgNPgl85+7pJ8NlXav7/ocAAAAIAnCVS+S63Pr4S+eKIchvfDBDn31D++roejE9hMyCiTDaK9eRXUMV8ee237Z6bbuE1+pyuqbWM2Khqum3Vab9+hlKcm0wG4qV/HTAjP7WJebq5O/2Nqy9sv7Fa7igl+0mpbMtretNu47V3R9DgAAAJAE4aqXOW14H/34c8fL7TS0aO0u/XRF3L5SLW3t2AeelHin+G6B/cZI/ce3X4+GqPg1VtnF7WErvlX73i3t5zRWWZ+7W3MVrYZF96SK7nflcFrVNSlxfy5J2vKmtODOxMrS/oSrYItU39ZoI9BobTKcTDR4tdQmvx0AAADogivVA0DP++Ipg5WX4dZNf/pA72yJCx7RcDH0DGnxz9qPx1euRl3Y3jZdal9PFV+5yu7XHqiccQ0v9m5tP6epSopEJH9bW/hk3QK9uda0wWgQaqmxPmcUSpmFbY/TIVw9dXHnF7xf3QJbEwOTv779OZI9Vmtt59sAAACAblC56qVOG25Nq9tc3ST/p+62Dk77ofV56FSp+Pj2k92Z7ZdHXdg+zU9qD06uDuEqvnKVLFw17rYqRNF1VMkqV9Fj0SAUnUqY1VfKaqtcBZv2vUdVsnAVTla52tn9fUxTaqVyBQAAgINDuOqlCrM8GphvVYlWDLle+uYGadzl1o2GIZ3+jbiTh1lT/YrHSf1PSB6uHHFFzqwOlatoYKrZ2n5OU1V7gHF62htZxK+58rVNR4xWrqIbAmcVWVUtR1vTjI5TAzvarzVXrVL99u7vE2hq707YsXJV8aG055PuxwEAAICjGuGqFxs30Aovq3fUSznFiTeO/ZxUNNJqHNHnWOnWldJXF1vByxsXrqIhKtDUfiyrqL1y5eqictVc0x6KohUqKbFbYLSDYDQIxVeuDCOuqUXb43S1Tmq/WrHvR+UqvtFF/O3Vm6TfTJXmnW5VtwAAAIAkCFe9WHRT4dU7kgQJp0v6f4ul29dYa6w8mdYxyaouRZtNRINTfCXH6U6+5irQEPcEplSz2boYH66SVq46TAvM7md9joarpraOgdGGHB0lDVcdNhGu35G4sXCyjoHxjxM/LXDNC22P2WJNdQQAAACSIFz1YtFNhVeU79Wq8lpVN/qtva+i3BnWR0eGIXnamlxEK1ThDmEloVtgh02Go/Zssj4nhKu2cw1He+OMWOWqLURF11tlRStXbY0uog0vOuquchUNc3s27/s+rfGVq9r2y5tea78c7YIIAAAAdEC46sWilavymhZ99tG3NelHr+ra+cu0q75Vz75XpvKaLjbolaTc/tbnaMDpyBXf0MKdeFs0eFVvtD4nhKuM9nOij5GsoYXUea+r2NorQyoYKh3/eetqd2uufPnWZ3+Hc5KGqySVq4ZKqfx/7ccJVwAAAOgCrdh7sT7ZXs389DH678e7VN8S0q6GVi3ZWK1Tf2JVYs4dU6zHr52U/M6XP2ntW1U4PPntzvhpgR0qV8VjrE1497SFq/h9tGL7Znnbq0rRqlhTW3CJhau2ClbZu1LlR9KAE6zrAydKN75mrYVa/dfuuwX68qTGys63tyaZFuhPUrla9w9JcdW+xl2d77cvjVXSRy9IE66yNnIGAABAr0S46uW+M32UvjN9lCTpox11+vKT/1Ntc1CStGFXQ9d3LBlnfXQU7SQYH67iNxh2Z1kNMnauaO+ul9DQoq1yFR+uQq1SONi+piqrbc1VdHrg2peszxsXWp+jFa3o4/rrrT21HHGF2JA/8ZyOklauatsvB5utx3jvycRzotW1A/HWHOndR6W3HrTWuHWs9AEAAKBXYFrgUWTcwDz945YzdNs5IyRJ1Q0d1mDtj/4TrM/RQOXyWFP0osZf2R6OopWgZGuuXPHTAv3tU/4MR3t1J7PDlMRoZSu6+W+0IYbMztP+olMNM/ITj0cfe19rriRp7cvS7nVWYIxOQTyYytW2t9vv+98fHvj9AQAAYAuEq6NMaWGm/t+njpEkNQXCqm+12pvvqm9VXVtFK6kZC6RRF0mX/da6Ht/QYvIt0nX/kGZ9LF08R8rum3jfZN0Cnd72xwg0tVeEMovaK1Adw1VU9LjL276GKz4sbV4s7d3W+bklaeSF1ud9dQuUpDdmW59PvFrqYwXSgwpXhtF++b35tHMHAADopQhXR6EMj1MFmdbUtIq6FtU2B3T2Lxfr7AcXd93kYujp0hf+JOUNsq7Hpvf5rMvDPtXeBCO7JPG+ycKVyyv1Pc66vOk1q3GE1L7eSuo6XMWvW4o+djQYbVsqPX2JtGlR5+cuPEY65jOJ58frGLhq2qY1Trq+vT1840FMC2yIW/MVaGjviggAAIBehXB1lOqfZ4WjitpWrSirVaM/pOpGv258erma/F1s1htv1IVWFWjSVzrfNmRy4vX4gJPTFsBySqSRF1gBqmGntOKP1vHoOquOl+PFh66O4ars3Q7Pnd9+efxV7dfj11dFJQtc3lyp78i4cHWAlatIuP0+0XVqNXFt4StXS3+4TNrxwYE9LgAAANIO4eooNSDfqiDtrGtJ2GT448oGPbBwvV74YLt+/p+P1RoMJ3+A3AHSF/8sDf9059sKhravzZISw1XpKdIXn5UuftiqXp3wJet4tGlFNMRI3UwLLOz82NFgtGtN4rnxAe34K9rXaSXrFpjsWL/R1rS+7GLr+oE2tGjaLZkRay1Z6anWsfhw9cHT0ievSR88dWCPCwAAgLRDt8CjVHzl6uNKq2vgWaP66b8fV+n3S7fGlgXtrG3RQ1edICN+3ZAk0zQ7HUsw+mKpYpV1OT5cGYY08vz26xP/T1r66/brXU0L9OW1B6iMbsJV1drEcWT2kT47V3I4pT7HSJFQ4vnxosccbinStv6s3xjrc3zlyjQT11F1p6Gi7f7FVhfFrUvapxtK7Rst15bv3+MBAAAgbVG5Okr1j6tcfdRWuframcfoovH9Y8HKMKSXVu7UU0u3Jtz3zr+t0gn3L9KO2paun2D0Je2XPVldn9fnGOms77Zfj19P5XRLF82Rpv1YOvbc9uNdTQsM+aXqDYmP7/JaDSkmfCHxfH9958YS0TVX0XVlklQ81voc7YAYDiSfUtiV6HqrnJL2PcPiK1fRcFVHuAIAALA7wtVRakBb5erD7XWqrG+VYUhj+ufqBxeP1fRxJbrvkrH67oVW1eaxxZsVDEckSaFwRC+v2qm6lqAWrUmyOW9U35FWwOp/glR0XPeD+dS3pHPus8LHyOmJt036P2nKLYnt3pNNC2yptYJVpMN6sY4bHEc3NDYjUqAx8bZo5Sp/cPuxaLhy+yRv23MdSFOLaOUqp3/ncBVsba9Y1ZbTRRAAAMDmCFdHqf55VuVqU5UVMI7tm60sr0t9c7ya9+WJum7KUH35tMEqyvaqsr5VC1ZbIWH9rga1Bq2g9e7mGknSjtoWzXl1g3Y3+BOf5Ko/SP9vcft+Vt054zbp1hVSyfHJby8Y0n45flpgfqn1+aPnpR3vW5fjA1XH53ZnWNP+pM5TA6NrruKrZ/1Gt1+Otpjf36YWkbBUHw1XcZWrPZutILV3q6S2QBVqkZpr9u9xAQAAkJYIV0epAfkZCdePH5jX6Ryvy6lrTrNCzb0vr9GXHn9XL6/aGbt92dYaRSKmZi9YpzmvbtSNTy+XPxQ+8I2J90e0cuXJad/AWLLWbOX0t9YxLfq+dey489pvNyOJj2MYcVMJ4xpYhINSsMm6HGhqPx4ftKJNLXZ/vO/xbn1L+lGx9ObPres5/dtfg79OatnbPiUwqq5s348LAACAtEW4OkoV5/oSrn/hlMFJz7v6tMHK8ji1tzmopZ/s0W8Wt68XqmkKaM3Oer3+cZUkaWV5rU68f5FO+uGirvfLOlgDTrTCyagLEo9n5FvrsqT2StSIuPVZ7sQQKam9Y2B8uGmpbb988vXW50EnJ95v2Kesz4u+L+1c0f1433qovSmGZFWuPJlSzgDres3mzuGKphYAAAC2RrfAo5TH5dAZxxbp48oGzb36JJ0yrDDpeUXZXv37G5/SW5uqdfeLq2PHfW6HWoMRPbhovZoCYWV7XWoKhNQcCKs5ENbiDbv15dOGJH3Mg+LNkW5dmbxL38jzpSvmW90J3VnS8VdaIabyQ2nw5M7nDz/TCjf/vM2qbK39u7TmBes2d5Z03PnSV9+wuvvFm3qHVL7Map3+h89J039hVaGOOVsqHNZ+3t6t1sbI8aL7exUda+3rtXNFYtdAKbGpRShgrQnLTP59AQAAQPqhcnUUe/orp+idu87qMlhFDe6TqS+dOlgTSvNjx75wslXpen291dzhcycO1L+/MVWnDbceK7qWq0d11/583OXSufdLZ37baj4x4hxp6qzk95n2Y2sfruY90l+vaw9WklQ8xrrPgBOtQBfP6ZI+/3tp4CRrWt8LN0j/+qY0b4r0wR+sc5prpDd+JslMXPuVU2J9Hn6m9XnTa9KetnAVrWZFK1fBVumJs6RfjpI2vdr+uB89b4Uuydp8eO4UafnvuvmCdfDhc9L889ufFwAAAD2KcHUUczgMuZ37/xb4vylDJUmlhRn6+lnHanhRe4v188aWaFRJri47yWpjvrGqodP9H1v8iU764SJ9XJlks942h2W9VkeeTOlLz0knfFkqGS+NOE+6/lXpq4ulL7/Q/X19udK1L0kjplkt4fuNlYLN0su3SK//RJpzvLTqz9a5Fz7Qfr+8tsYb0ZbyWxa3b3gcDVzRytXrP7bCU9gvPTfDqsg9c7X0t69If79ZCoekl26SqtZY4e6th6QF32prkNGFuh3SP26Tyt6R/vENOhMCAAAcBoZ5RH6btZf6+nrl5eWprq5Oubm5qR5O2ohETD31zlYdPzBPk4YWqrrRr1v+/IEipvSnG06V2+nQB2V7ddncpSrO9ep/d58jSWryh+R1OXTyj1/V3uagvnL6MH3/4jGdHn9XfasufHiJzhrVTz+/YsKRfnkHJxKR/jVLej+ugtR3tHTa16STrrWCUcgvDT7Vus00rYpUY1sb+7xS6bwfS89dK+UOtLoTbnpNkin1GSHt2Zi4qbFkVdWSrfnKH2xNVWzeY22avGWJ1YVwxDRp9d+kTYvaz710nnTCl6zxVK2Tdn1kTUMcdZHV6KN6g9VCP3eAZDja9gAzrDVuTrd1vzUvWKFt4nXtTULiN1hu2mNNfSwaIfnyrT3C4rs3RhuKeLIlB3/nAQAA6elAsgHhKgnC1cGrbw1q/L0LJUkf3jtN/1ldqTuf/1DnjS3WK2usFubDi7L03zvO7HTfp9/Zqu//fY1yfC59+INpMrqbBphOQn7pyXOtIHXMWdIX/mJNTezKSzdLK/9oXb5ivlQ0Unrs9MRzTv2aNcXxT5+Xtr9nHRt+prT5jfZzpv1YWvuSVLddMpxS/fbux2k4rOmTq/9qXR88WarfKdVuaz+nY5DryOG21qJ5Mttb3/vyrMBXt12q2WIFxJa9Uv2O9ud1Z1rhzZNtdV2MhNqf1+WzAlhOf8npsRqT1GxpawBSImUWWfcNtVpdHRt3WY+XUWCFOTPc1hXSsCqLoVZrGmXLXuv5vNnWbQfKcLQFRaP9smlKMuMqf+b+VwH3+X7ejzH2xGMAAA6MXX4f6a2u+mPK16AfSDagoQV6VK7PreJcr3bV+7W+skG/em2jJMWClSRtrm5S2Z5mDe6TmXDfpZv2SJIaWkPa0xRQUfZ+7I+VDlxe6dqXral+I87rPlhJ0thLrXA15HRp7GVW0Bg8WWrabYWf8VdJfY6xzr3279Ir91gB5LyfWM9Rtdaakjj+KmuDZcmaEvjnL1jt5AuPsapExeOssWxZYlWgTviSNS3Rk21V2sreaRu/Txo40QowFausINF3lBVwQi2JY48Epd3rrMtOj1V5q/kkMfTt+qj9clY/qamqfcPmQKNU02E9XqjVmgZZuVqdVG/o/msJAAB6t3A3f/RNQ1SukqBydWi+/MT/9Namap05sq/eaGt4EZWf6VZtc1DXnDZE08YW6/RjiuRwGApHTJ30w0Wqa7H+Af1t5mRNGtqLO+Vtf1/qO7KtqpICFR9KFSulvEHSoFOscZimtHu9VYnK7W9dDzRaVSFvrnW9fod1Tu02qzV94XCrg+LeLdbUv74jrX3AMgqscOfLtTZSDjRZf3VqrrEqT5GQ1VTE5bMes3qjFcLCQasq1ecYK3Q1VEpN1VZzEXeGFfyyi611bq111vRHw2FV7syIdczltcKnL98af6DpwP/qGKtQRdqqYxHruoy4alb0MY19P/4+f8zux4/hQ30MftQDAOzouPP3/Yfrw4xpgYeIcHVo7n15jX6/dGvs+mdPGKBX1+5S3xyvPj+pVL94ZX3sthNK83XumGL53E798J9rY8d/ccV4fX5S6ZEcNgAAANAJ0wKRUiOK26sxfbI8uufC0brnwtHyOp1qDob0t/e3yzCkXXWtWlleq5XltZ0eY0t10xEcMQAAAHDoCFfocZeeMFCryms1MD9TXzy1VP1y2ku5eXLr9bZmFlX1rXr2vXKt39WgBasrFDGlEf2ytbGqUVv3EK4AAABgL4Qr9Lgsr2u/Wqn3y/Xp62ePkCTtqG3R2p31chjS9U8t1+bdhCsAAADYC+EKaWFgfoYG5mfEpgNu29OsSMSUw0H7UwAAANgDO3cirQwqyJDTYaglGNauhtZUDwcAAADYb4QrpBW306HSggxJNLUAAACAvRCukHaGFWVJIlwBAADAXghXSDtD28LVVsIVAAAAbIRwhbQznMoVAAAAbIhwhbQzlHAFAAAAGyJcIe0M7WOFq7KaZoUj5n7fzzRNBcORwzUsAAAAoFuEK6SdAfkZ8rgcCoZN7djb0uV5z75XpgcXbVCkLYA99OpGjfn+f/TRjrojNVQAAAAghnCFtON0GBpSmClJ2rIn+dTA8ppm3fXCaj382ka9s3mPJOmfq3YqGDb1n48qj9hYAQAAgCjCFdJSrB377sbYsTc37Naz75XprY3V+sO72xSdMfjSih2qbw1qc9sarQ+pXAEAACAFXKkeAJBMNFy9vn63Lhw/QGsr6nXd/GVJz/3PR5W6cHz/2PUPt9dqT6NftS1BHdM3+4iMFwAAACBcIS2NG5gnSVq8YbfOeuAN5fist+qokhxt3dOk1mBEgwszFQpHtLOuVb96bWPsvrXNQV3w8BLtaQzopZtPjz0WAAAAcDgRrpCWLhrfX4YhzXvjE63ZWa8Gf0hF2V79deZk7W0K6k/LtunC4/vr3x9Vat4bn2hFWW3C/XfV+yVJv3lzsy6ZMEA+t0NTR/RNwSsBAADA0cIwTXP/e10fJerr65WXl6e6ujrl5uamejhHtWA4op/++2O9uGKHfnrZ8Zo2tiTh9t0Nfp35i9fVFAhLkob2ydTWPc2dHsfrcmjl96cpw+M8IuMGAABA73Ag2YCGFkhrbqdD37tojN7/7jmdgpUk9c3x6vozhsWuf/GUwZKsMHXi4PzYcX8oom01bEoMAACAw4dpgbAFwzC6vO1rZx6rFeW1Ki3M1FUnl+r19VU6f2yJTh5WqLtf/EirymslSVurmzSqhEokAAAADg+mBSbBtMDe5RvPrNDfV+7Ut88fpa+deUyqhwMAAAAbYVogEGdoH6ut+9ZqpgUCAADg8CFcodeLbUi8h3AFAACAw4dwhV5vaBGVKwAAABx+NLRArzesbVpgVYNfn33kLeVlevTZCQN02UkDZRiGymua9Y8Pd6ow06PPjOqn4lxfikcMAAAAOyJcodfLy3SrINOtvc1BrdpeJ0l6c8Nu7W0OaMyAXN30pw9U2xy0zs1w64/Xn6oxA3I143fLtH1vi/42c7L6ZHtT+RIAAABgA4QrHBWa/OHY5asmlerZ5eWa/e+PFY5YzTJHleQoHDG1sapRX3riXV0wrr+WbKyWJN3z4keqawkqP9Otn3zueHndDmW4nd22hwcAAMDRh3CFo8LVpw3W797equvPGKbvXjhaDf6gFqyulCRdOWmQ7v/sOIUipr7yu/e0bGuNnl1eHrvvf9ZUxi6/sX63WoJhXTlpkH5+xYQj/joAAACQvtjnKgn2uep9mvwhrdlZr5OHFsgwDDX5Q/rLsjKdPLRQE0rzY+e1BsP69vMf6u8rd2rSkAIN6ZOl5z/YruOKs9UajKisplmS5HU5tOoH0+RzO1P0igAAAHAkHEg2IFwlQbg6upmmqQ+31+m44hy5nIbe3LBbpw7vI4chrato0C1//kAVda166iun6NPH9U31cAEAAHAYsYkwcAgMw9CE0nxleJxyOx06e3Sxsr0uZXpcmjikIBaoFq/fHbvPfz6q0IzfLdP6yoZUDRsAAAApxpor4ACdObKvnnmvXP/9eJdOP7aPdjf49d2XPlIoYqq8plk/v2KC/vZ+uRau2aUrTy7VneeNlGEYCoUjipiSx+XQtj1N+uO72xQxpe9MHyW3k79zAAAA2B3TApNgWiC6U98a1In3L4p1GowyDCnZv6aLxvfXccU5emzxJ4qYpkpyfdq6pzl2+x3TjtMtZ4043MMGAADAQWBaIHAY5frcmjFlqPrleDVuYK5GFufoS6cO1hPXTpLTYcjtNHTxhAH65rnHyWFI//ywQg8u2qDmQFitwYi27mmWYUgTBuVJkn712kat3Vmf4lcFAACAQ0XlKgkqVzhYZXualeV1xjYd/t/mPfrb+9u1dU+Trpg4SCeUFmhnXYtOLM1XXoZbNz79vl5dt0tF2V79+cZTdVxxTopfAQAAAOLRLfAQEa5wpOxtCujqJ/6ntRX18rgcuuj4/nI6DG3a3aj6lqCG983WZ08YoM27m/Tax1UaWZytqga/6luCunziIF0xcZC8LtrBAwAAHC6Eq0NEuMKRVNsc0Mw/vq93N9cc8H0nDSnQ/P87Wbk+d+zYpqpGPf/Bdk0cXKCzR/eTaUqLN+xWoz+kEwfna1BBZk8OHwAAoFcjXB0iwhWONNM09c7mPXprY7Uy3E4NKcpSQaZby7bU6PdLt8rjdOjmzxyrXQ2tKsz0yOkw9PBrG1XfGlKO1yWv26mIaSpimqprCcYaa4wszlEoEtEnu5tizzVpSIHOH1eiM0YUaVRJbsIYVu+o06trd6kpENa1k4doSJ+sI/2lAAAANmCapkxTcjiMVA/lsCNcHSLCFdKJPxSWpE7T/9bsrNN1899TdaO/031OHVaoFeW1CoQikqQcr0vD+mbpox11im9yOG5grupbQpKkLK9L6yraG2t4nA6NHpArfzCszdVN8jgd8rmd6pPl0eRj+qihNaSIaWrikAK1BsNau7Nee5sDumJiqQxDWldRr/qWoPIy3NrdGFBZTZNG9MtRboZbLoehoUVZavKHlOF2alT/HL21sVrhiKncDLfWVdTLYRjKz3SrT7ZXZx7XVx+U7dV7W2t0xrF9debIvvK5nWoOhPTMsnI1+UM6e3SxRhRn693Ne/TOJ3u0tzmos0f109mj+8kwDLUEwgqEI8rxumQYUllNsxyGoUEFGXpzY7VqmwMaOyBXLodDEdMaR1G2V4FQRKas/0De3LBbBVkeTRxcEPvPpNEf0ntba1RakKkB+b7Y1y/D7ZQ/FNGanfXatqdJA/MzdMLgfL2xfrf2NAaUn+nWmSP7KtPTviNGVX2rDMNQltep8poWDemTKZ/bqdZgWJt3N+mT3Y0KhiOaPq6/AqGIymqa5XU7NLwoSzXNAb3yUaXe3VyjM0YU6YunDJZk/ecnWfu3fbi9VjtrWxLeKzk+t44rzlFRtie2ZcCGXY0a3CdT4Yipf6+ukGFIpQWZGlqUpZqmgIb0yVR1Y0BPLd2qS04YoJMGF6iyrlU7aptVkOnR0D5Zsa9PazCsJn9ImR6X3t+2VztrW3TOmGIVZnkUCkdU0xTQ7ka/sr0uDS7MlGFY93trY7V+8+YnmjamWFefOkSmpG17mmQYhlwOQ+U1zWoKhJWf6daEQflq8ofkMAzVtgT034+rVJTt1bCiLDUHwirM8mhwYaY8rvYeToFQRFv3NKk5EFZJrk8leT5t29OkJn9YTYGQ1u6s17iBuTppcIEa/CEt21yj3Ay3jivO1rItNcrxuTVuYK5y4qrGjf6QNu5q0NJP9igcMXX1qYNj6y8lq0rtcBhyGIa2VjdpWFGWGv0hLf2kWhMG5Wt43+zY96yyvlX+YERD+lhfk2VbarT0k2pdO3moVpXXakV5ra44aZAG92mvRO9tCqiuJSiPy6GSXJ9qmgOqrGtVIBzRmP658rmdscePfp0jEVMvr9opSTp/XIl8bqdqmwNaV9GgQQUZGpCfobc2VWvJht26bspQVTf6taKsVl84pVSZHpciEVM7alvkdTuUl+GWy+HQ3uaA8jPcMiV9tKNOe5sD6pfj08D8DC34qEIZbqcmH9NH/fMy5A+FtW1Ps/Y2BdQv1yef2yF/MKJAOCJ/MKKqhlbtrGvV8KIsnVCaryyvS6ZpqrzGeh9HX38kYmr9rgZt29Ok4wfla2B+RsL73B8K6+OKBhVkelSS59PGqgaVFmbKjEirttdq7IBc7W70a+OuRp0/rkRup0NN/pDe2lStklyfhvfNktvpUGVdq3bWtWhnbav2NPo1aWihThqcH/t6dhR93vxMtwbmZ8jldKihNahn3ytXdWNA158xTEs27lZTIKzxA/O0o7ZFo0pyNLxvdtu/G2enx47//kV9XFmvjbsaFTFNFedaX2unw9DuBr9GllhreXc3+DWoIEOmKdW1BGUY0hvrd8vhMDRtTLF8bqcq61pVWd+qMf1z5XE55A+FtXp7nRpaQ+qb49Wokhy5nA69sb5KH5TVakhhpiaU5svrcmj73hZleJwKhiPyuZwaOyBX1Y1+ra2oV11LUJOGFmpgfoYa/SGtKq9VKGLK43Qoy+vUiH45MmWqsq5V+Zke5We4tX1vi5Zvq9GkIYUqLcxQcyCc8PUwTVON/pD1/4bPHfuZEwhFtLK8Nvb+rW8N6g/vbFO/HK+umDhIe5uDuuOvq7R1T5PmX3eyWkNhbdndpD7ZXo0ZkKtsb9e7FG3c1aA9TQGdPLRQjf6Qqhv9GlKYqZqmgDI8TuX43PKHwopEJK/LkRA69jT69eKKHfK6nZo0pEBZHpc8LoecDkNet0O5PrdWlO3Vu5trdNH4/irO9am60a+9zQF5nA4NLMiQwzD0xvoqFWZ5NWlI+/9D/lBYG3c1alRJjhZ8VKm1O+t1/RnD1DfHG/vZMP/tLeqX49WVJ5fK63LKNE21BiOqbvRrZXmtfG6nThlaqNwMlwzDiH19s72uhPdba9D6nSQQjuiaJ5epoTWop/7vFO1u9Ms0TY0oztHHFQ0aVpSlvjlehcIR7W0Oxn6XkaS+OV55XU5FIqZqW4LKcDuV4bF+PjW0BtXoD6l/XkbsevzP2VQhXB0iwhXsoiUQ1ubqRjnbfmFzGFJuhlv9cnzaVd+qleW1ag2G9akRfVWQ5dGu+lb9feUOvfPJHr21qVrBcOI/f4/LoXNHF6u+NaglG6tT9Kr2zekw1D/Pp4bWkOpagrHjDkPq0CFfo0py5HU7tWZHnUIRU4Yh+VxOtbT9BzG8b5Y2x1X24o3ol62ymmYFwxF54+6Tn+lWYZZHEwbla9mWGu3oEFgkyed2KBKx/gOKynC3P0b0+qCCDOVmuNUcCCeEW0kqyvZoSJ8srSjbm/C6irK9qm8Jxh47x+dScyCcsD3AyUMLtLGqUXUtQZUWZGpkSY4Wrd3V5de0MMujfjle7W7wa09TQEXZXvnc1i9MHeX4XJIpNfhD8rgcGt0/V6vKaxMe66xR/fTBtr3aXN35a+tzO5TtdWlPUyBh+wKf2yG3w6HcDHfC1zQvw63WYFj+UKTTY0ldb4MQL9Pj1MlDC5XtdWnrniZt2NWQ8P4fXJipsprmTvfL8jjVFAh3Oi5Z378Zpw/V5t2NWlVep8r61oTbc3wuZXlcCoYjcjkN7ar3d7o9EjFjj1+Q6VY4YioYNmPvk7wMt/rleLWxqlGSVJLr066GVpmm9boHFWQoP8Oj2pZALHBI1h9H4t97PrdDgwoy1RoMa1fbOPvl+JSX4dbatvddYZZHn580SM+9V669zda/K5fDUKjtfZXjc6nJH1LElIYVZemYvtn6oGyvapoCseeJfi9yfC65nY6kt0nWv+HLTxqo/35cperG9nO6k+F26oTSfG1o+wVXsv6QNG5gnl5fXxX7d1yU7dUfrj9Fq8prNf/tLdpa3aywacb+fbidhoJh6xd7w5D8oUjCz45JQwo0dURf/el/21TV0PmPVx0VtP08yM/06Ji+WcrxufXmht1yOgztqG1RQ6v1B6xMj1ODCzO1dU+TWoORTl+TKKfD0HHFOVpXUa/CLI8GFWSooTWkhtag6ltDCoQiynA7lemxfn4MKszUvz6s6HJ8RdkeRUyppimg0f1zVdscUEVd4ns11+dSjq/9312mx6nhfbO0fW+Lapvbf8Zme10aPyhPSz/Zs8+vS2GWJ+H7L1n/nlpDkU5bmTgdhiJtVRAp8We502EoL8OtmqaAcrwuFWZ7JElV9f7YvxOHIeVnelSQaZ0Xff8O7WMFn/q278E5o/tp7c567Wx7/X2yPKppDiQ8b4bbKVOKjSfH59KAfOt7sKXt59nI4hyV1TSrJRiOfQ8NQyrOaf/3mZ/p1jmji7Wuol7VjX7VtQRj3/dkTijN1+oddZ2+NlEel0M5bT83JevfuMMhnT26WOsrG7SpqlE5Xpca/NZrzfG5lOmx/sgXDEViP2dyfC4Zkpo6/J8R5XIYyva5FApb4aog061Mj0tVba8rFDHldTk0pE+mNuyyfi5lepxq7vBz0ukwNCDfpx17Wzr9v+xyWH883dscVLgtZI8flCdT0ofbaxUMm5owKE8NrSHtrGvRhz84L+GPY6lAuDpEhCscDarqW/XGht0a0PbXoYq6Fn1mVD8VZXtlmqY27GrUluomuZ2GRvTLUcQ01RwIa+ueJr27eY8KMj2KmKZWltcqL8Ot4X2zFY5E9Ox75cr1uXXq8D4qyHSrriWoLK9Lw4uytKmqUf5QRC3BsLZWNyk3w63Kulatq6zXqcMKVZTtVW1z0KogOQ3tbQ5q8+5Gvbu5Rpkep6aP66+3Nu1O+CW1tDBDx/XL0dufVKs1aFWmph9fIo/LoWffK+8UIKPcTuuXRrNtY+eRxTnaUt0kQ5IMqwrR8afjwPwM1bcEY/95RfXJ8qjRH0r6y3/fHKuC8uH2WrUGIyrO9WrCoHx9XNnQ6Zf56B8HTdP6q2f84+VluHVsv+y2ClFL7LFbAmE1to3nhNJ8HVecreeWb0/6mh2GNKE0X864v0LuaQpo656mhNfqdBix/3QH5mfouOJsbaxq1I7aFmV7XbFfFvMz3bFfvJwOQyVtf2ntKgQVZFrBf/2uhoTX3CfLo/qWUEIYkKTzxhbrrY3VsV8KfG6HnIb1i/Ggwgzl+NzaXtMc+2Uj+ninDeuj+tagdtX7leV1qrrBnzQg5XhdyvG5Yr9oWf/he2QY1i9P722tib2WYW1Vu7qWoIYXZak1GI7dL15RtkcnlBZo+95mfVzZ0On2qGyvK/Z9Ky3M6PQLiNNhyOkwYtVnw5DyM9yxXxpHFuckfB3jX1NLMBz7Q0LfbK8ippJWuKMy3E4VZLoTXk9h23s6EIrI43JoYH5G7BfL+LFL1i95wUgkacAtyHRrYEGGNu+2qoSjSnLkdTm0antd+5h9LvXJ8mhXvV+hiPWHDK/LIa/LobxMj/rn+bS+siEhcLudhiKmEn45zPJYf/3uKqwVZLrV0BpSKGIm/DJYlO1VdaNfLochj8uR8Etica5XrcFI7I84GW6n+uf7NCAvQ5kep97cuLvbX5il5H8cOKZvlgzD0KaqRhVlezS8b7Y27GpQcYd/Hwdi4pACeZwOVdZbPyPCba8z+u81mWP6Zqkl0P5eNgxru5H4P1oVZXtUnOtTeU1zLKRI0vRxJdrTGNDK7bUyTVODCjLlD4blcTlU3RhQoz8kw7D+SJXhdurDHXWx98igggzlZbjlD0VU2xyIfc/ivy8OQzq2X3bsF/gDkd/2f0/0+QbmZ2hnXUvs+pA+mQqFzdh7atzAXNU0BpL+m47X8T0SDerJ/rCXzNgBucryuLShqkGBUESBUCT2x4uoEf2yY39Mif5MCoTCsa99ca5Xzf5wp/+HojxOh0oLMxKWA0jWz4y9zYFOfzBwOQyNGZCbEB73l9flUEGmR5X1rfI4HfK6HWpoDako29Pp36G3LRyZpjr9rO+o4x8d/nXrGRo7IO+AxtbTbBWu5s6dq1/84heqqKjQ2LFjNWfOHE2dOrXL8xcvXqxZs2ZpzZo1GjBggO68807NnDkzdvsLL7ygn/zkJ9q0aZOCwaBGjBihb37zm7rmmmv2e0yEK+DISjbNJV51o18+t1PZbVOCdtX7E/5T9LqcCkdMVdS1tFVcrOkFO2tb9NGOOvlDEZ1Qmq++OV7VtwbV5A+rf55PZTXN+vfqSl04vr+O7Zed8JxVDa36YNteDe+brfwMt/Y0BTSyOEeBcESbdzeputGvtz+pVo7Xpf87fZi8LkcsyEVMU9WN/ti0Q8MwtKfRry3VTRo/KF8elyMWYPc0+VXfElIoEtFpw/so22tVoXJ9Lr26bpdqm4M6Y0SRBuZbj9MaDGtxWyg+flCewhFTa3fWK9vn0rAia43cfz/epVXldfrUcX01MD9Di9Za0wW/csZQTRxS2Onr2xII65PdjdrbHJC3bTrP797eoqoGv7557kjlZVpTMiJtvwQsXFupirpWffGUwXryrS1q8od03ZShKs71KRiO6O1N1Vq8YbdGleRo2pgS5Wa4Y9NLHIa0rsL65bFvjleFWZ5YiNhZ2xJbN5jjs8JkfWtQO/a2KMvj0sACa6pTx2ltVQ1+5beNMRQxO03rMU1Ta3bW68PtdWoNhjUg36exA/Ji35vymmat2Vmvk4cWJEzja2gNqqrBr4JMjwqzPAqErF+y++ZYf4B4ccUO/X3lTo3un6tzx/TTsX1zYl+rUDii97buVYbHCgotwbBG9MuW02HIH4woL8OtxRt3yx8Ma9qYEu1tDqimyZo26DQMleT55DAMbaxqUFW9X0P6ZCrD49RPFnysE0vz9X+nD1V1Y0BbqpvU5A/J53ZqzIBc5WW4FQxHVFHbqj7Zntg0ug27GlXTFJDHZag413rsT3Y3avPuJp01qp/65/n00sqdmv/WFp04OF/fu2iM3E6HKupalONzy+ty6DeLN2toUabOPK6fnlteLrfT0JgBeTpxsBXYG/wh+UNh5Wd4tK6iXq3BsCYOKZDL6VBrMByblmYYhhauqdQTb23RZ0b20/VnDNvnX6VN09SK8lp9XNGgUf1zNKZ/rmqaAlqwukIVda0aVJChz08qVXMgpCvmvaOymmYN7ZOpq08dEpvmV5zrVaM/pD2N1tTWTVWNCoZNje6fo4q6VmW4naprCepXr22UJE0aWqArJg6Sx+lQa9tUxVxf4hSpJn9IZTXNse/f6h112tsU0Jkj+ynT41SOz6UTSwskSRuqGrS9pkVDi7I0vChLoYipZVtqNKE0L2Ha0/vbavRJVZOmHNtHu+r92tsUUE5bZSnH55LX7VBrIKKmQEgflO3Vuop6XXj8AE0+pk/C1ytiWj+L3txgTf07fmCeFqyuiFWWQxFTOV6XQhFT6yrqFQybGtInU4WZHm2salRZjbW1yKnD+liVpYipD8r2atHaXZpybJE+fVxfSVKw7Rdlt7P9e9gaDGtVea2G9c1SvxxrunRdc1B7m63pc8W5voSxVta3yukw1C/H+hmytykgt9OhgiyPNlU1qqE1qOFF2drd2Kra5qAiptQvx6t+uV65HA7VtgS0tylo/RsyrKBZ02T9+3A6DE0ozdeSjbv1rw8rNfmYPjp/XIkq61r16OubNH1ciaaNLZFkTZ1sDlhTjCXrl/za5qAq6lqV5XVqZHGOgmFTT7+zVRNK83XO6GJVNbSqT5ZXe5sDKq9p1tCiLPncTi3fWqMlG6s1ssR6vzoMQ6P75yT9v2773ma9+MEODe+brQvH91d1o19Ow6rYOdp+5m2satSOvS2acmyf2Fj3NAb0+6Vb5XM7dPs5x+mjnXUaXpStQQUZ1h8lvVaFsyUQ1vED8xSKmNpU1Sif23pvZntdynA7Y9MLm/whNbSG1OgPyjAM9cvxamt1swLhSNvPJGsJwbLNNfrLsjJ98ZTBGlmSo7+9v12XnDBAgwszVdcSVFG2V1uqm1RZ16rhfbPUJ8sjl9MR+35X1LVqb7M1Q6Iwy6Oymmat3l4nl9PQyOIc5WW49drHVSrO9eqkwQXKz/R0+/PhSLBNuHr22Wd1zTXXaO7cuTr99NP1m9/8Rk888YTWrl2rwYMHdzp/y5YtGjdunG688Ub9v//3//T222/rpptu0l/+8hddfvnlkqQ33nhDe/fu1ahRo+TxePTPf/5T3/zmN/Wvf/1L55133n6Ni3AFAIA91bcGVVHbquOKs7v9ow0A7C/bhKtTTz1VJ510kubNmxc7Nnr0aF166aWaPXt2p/O//e1v6+WXX9a6detix2bOnKlVq1bpnXfe6fJ5TjrpJF144YX64Q9/uF/jIlwBAAAAkA4sG6RsdVggEND777+vadOmJRyfNm2ali5dmvQ+77zzTqfzzzvvPC1fvlzBYLDT+aZp6rXXXtP69ev1qU99qucGDwAAAAAddN1v8jCrrq5WOBxWcXFxwvHi4mJVVlYmvU9lZWXS80OhkKqrq9W/f39JUl1dnQYOHCi/3y+n06m5c+fq3HPP7XIsfr9ffn/7Ar/6+vouzwUAAACAZFIWrqL2Z/+GfZ3f8XhOTo5WrlypxsZGvfbaa5o1a5aGDx+uM888M+ljzp49W/fdd99BvgIAAAAASGG4KioqktPp7FSlqqqq6lSdiiopKUl6vsvlUp8+7V1yHA6Hjj32WEnSCSecoHXr1mn27Nldhqu77rpLs2bNil2vr69XaWnpwbwsAAAAAEeplK258ng8mjhxohYtWpRwfNGiRZoyZUrS+0yePLnT+QsXLtSkSZPkdne9e7NpmgnT/jryer3Kzc1N+AAAAACAA5HSaYGzZs3SNddco0mTJmny5Mn67W9/q7Kysti+VXfddZd27Nihp59+WpLVGfCRRx7RrFmzdOONN+qdd97Rk08+qb/85S+xx5w9e7YmTZqkY445RoFAQAsWLNDTTz+d0JEQAAAAAHpaSsPVVVddpT179uj+++9XRUWFxo0bpwULFmjIkCGSpIqKCpWVlcXOHzZsmBYsWKDbb79djz76qAYMGKCHH344tseVJDU1Nemmm27S9u3blZGRoVGjRumPf/yjrrrqqiP++gAAAAAcPVK6z1W6Yp8rAAAAAJJN9rkCAAAAgN6EcAUAAAAAPYBwBQAAAAA9gHAFAAAAAD2AcAUAAAAAPYBwBQAAAAA9gHAFAAAAAD2AcAUAAAAAPYBwBQAAAAA9gHAFAAAAAD2AcAUAAAAAPYBwBQAAAAA9gHAFAAAAAD3AleoBpCPTNCVJ9fX1KR4JAAAAgFSKZoJoRugO4SqJhoYGSVJpaWmKRwIAAAAgHTQ0NCgvL6/bcwxzfyLYUSYSiWjnzp3KycmRYRipHo7q6+tVWlqq8vJy5ebmpno4sAHeMzhQvGdwoHjP4EDxnsGBSpf3jGmaamho0IABA+RwdL+qispVEg6HQ4MGDUr1MDrJzc3lhxEOCO8ZHCjeMzhQvGdwoHjP4EClw3tmXxWrKBpaAAAAAEAPIFwBAAAAQA8gXNmA1+vVD37wA3m93lQPBTbBewYHivcMDhTvGRwo3jM4UHZ8z9DQAgAAAAB6AJUrAAAAAOgBhCsAAAAA6AGEKwAAAADoAYQrAAAAAOgBhKs0N3fuXA0bNkw+n08TJ07UkiVLUj0kpMibb76piy++WAMGDJBhGHrppZcSbjdNU/fee68GDBigjIwMnXnmmVqzZk3COX6/X1//+tdVVFSkrKwsXXLJJdq+ffsRfBU4kmbPnq2TTz5ZOTk56tevny699FKtX78+4RzeN4g3b948jR8/PrZh5+TJk/Xvf/87djvvF+zL7NmzZRiGbrvtttgx3jeId++998owjISPkpKS2O12f78QrtLYs88+q9tuu0333HOPVqxYoalTp2r69OkqKytL9dCQAk1NTZowYYIeeeSRpLf//Oc/14MPPqhHHnlE7733nkpKSnTuueeqoaEhds5tt92mF198Uc8884zeeustNTY26qKLLlI4HD5SLwNH0OLFi3XzzTfr3Xff1aJFixQKhTRt2jQ1NTXFzuF9g3iDBg3ST3/6Uy1fvlzLly/XWWedpc9+9rOxX2x4v6A77733nn77299q/PjxCcd536CjsWPHqqKiIvaxevXq2G22f7+YSFunnHKKOXPmzIRjo0aNMr/zne+kaERIF5LMF198MXY9EomYJSUl5k9/+tPYsdbWVjMvL8987LHHTNM0zdraWtPtdpvPPPNM7JwdO3aYDofD/M9//nPExo7UqaqqMiWZixcvNk2T9w32T0FBgfnEE0/wfkG3GhoazBEjRpiLFi0yP/3pT5vf+MY3TNPk5ww6+8EPfmBOmDAh6W294f1C5SpNBQIBvf/++5o2bVrC8WnTpmnp0qUpGhXS1ZYtW1RZWZnwfvF6vfr0pz8de7+8//77CgaDCecMGDBA48aN4z11lKirq5MkFRYWSuJ9g+6Fw2E988wzampq0uTJk3m/oFs333yzLrzwQp1zzjkJx3nfIJmNGzdqwIABGjZsmL7whS9o8+bNknrH+8WV6gEguerqaoXDYRUXFyccLy4uVmVlZYpGhXQVfU8ke79s27Ytdo7H41FBQUGnc3hP9X6maWrWrFk644wzNG7cOEm8b5Dc6tWrNXnyZLW2tio7O1svvviixowZE/ulhfcLOnrmmWf0wQcf6L333ut0Gz9n0NGpp56qp59+Wscdd5x27dqlH/3oR5oyZYrWrFnTK94vhKs0ZxhGwnXTNDsdA6IO5v3Ce+rocMstt+jDDz/UW2+91ek23jeIN3LkSK1cuVK1tbV6/vnndd1112nx4sWx23m/IF55ebm+8Y1vaOHChfL5fF2ex/sGUdOnT49dPv744zV58mQdc8wxeuqpp3TaaadJsvf7hWmBaaqoqEhOp7NTAq+qquqU5oFol53u3i8lJSUKBALau3dvl+egd/r617+ul19+Wa+//roGDRoUO877Bsl4PB4de+yxmjRpkmbPnq0JEyboV7/6Fe8XJPX++++rqqpKEydOlMvlksvl0uLFi/Xwww/L5XLFvu+8b9CVrKwsHX/88dq4cWOv+DlDuEpTHo9HEydO1KJFixKOL1q0SFOmTEnRqJCuhg0bppKSkoT3SyAQ0OLFi2Pvl4kTJ8rtdiecU1FRoY8++oj3VC9lmqZuueUWvfDCC/rvf/+rYcOGJdzO+wb7wzRN+f1+3i9I6uyzz9bq1au1cuXK2MekSZN09dVXa+XKlRo+fDjvG3TL7/dr3bp16t+/f+/4OZOKLhrYP88884zpdrvNJ5980ly7dq152223mVlZWebWrVtTPTSkQENDg7lixQpzxYoVpiTzwQcfNFesWGFu27bNNE3T/OlPf2rm5eWZL7zwgrl69Wrzi1/8otm/f3+zvr4+9hgzZ840Bw0aZL766qvmBx98YJ511lnmhAkTzFAolKqXhcPoa1/7mpmXl2e+8cYbZkVFReyjubk5dg7vG8S76667zDfffNPcsmWL+eGHH5p333236XA4zIULF5qmyfsF+ye+W6Bp8r5Bom9+85vmG2+8YW7evNl89913zYsuusjMycmJ/X5r9/cL4SrNPfroo+aQIUNMj8djnnTSSbEWyjj6vP7666akTh/XXXedaZpW+9If/OAHZklJien1es1PfepT5urVqxMeo6WlxbzlllvMwsJCMyMjw7zooovMsrKyFLwaHAnJ3i+SzN/97nexc3jfIN5XvvKV2P85ffv2Nc8+++xYsDJN3i/YPx3DFe8bxLvqqqvM/v37m2632xwwYIB52WWXmWvWrIndbvf3i2GappmamhkAAAAA9B6suQIAAACAHkC4AgAAAIAeQLgCAAAAgB5AuAIAAACAHkC4AgAAAIAeQLgCAAAAgB5AuAIAAACAHkC4AgCghxmGoZdeeinVwwAAHGGEKwBArzJjxgwZhtHp4/zzz0/10AAAvZwr1QMAAKCnnX/++frd736XcMzr9aZoNACAowWVKwBAr+P1elVSUpLwUVBQIMmasjdv3jxNnz5dGRkZGjZsmP76178m3H/16tU666yzlJGRoT59+uirX/2qGhsbE86ZP3++xo4dK6/Xq/79++uWW25JuL26ulqf+9znlJmZqREjRujll18+vC8aAJByhCsAwFHne9/7ni6//HKtWrVKX/7yl/XFL35R69atkyQ1Nzfr/PPPV0FBgd577z399a9/1auvvpoQnubNm6ebb75ZX/3qV7V69Wq9/PLLOvbYYxOe47777tOVV16pDz/8UBdccIGuvvpq1dTUHNHXCQA4sgzTNM1UDwIAgJ4yY8YM/fGPf5TP50s4/u1vf1vf+973ZBiGZs6cqXnz5sVuO+2003TSSSdp7ty5evzxx/Xtb39b5eXlysrKkiQtWLBAF198sXbu3Kni4mINHDhQ//d//6cf/ehHScdgGIa++93v6oc//KEkqampSTk5OVqwYAFrvwCgF2PNFQCg1/nMZz6TEJ4kqbCwMHZ58uTJCbdNnjxZK1eulCStW7dOEyZMiAUrSTr99NMViUS0fv16GYahnTt36uyzz+52DOPHj49dzsrKUk5Ojqqqqg72JQEAbIBwBQDodbKysjpN09sXwzAkSaZpxi4nOycjI2O/Hs/tdne6byQSOaAxAQDshTVXAICjzrvvvtvp+qhRoyRJY8aM0cqVK9XU1BS7/e2335bD4dBxxx2nnJwcDR06VK+99toRHTMAIP1RuQIA9Dp+v1+VlZUJx1wul4qKiiRJf/3rXzVp0iSdccYZ+tOf/qRly5bpySeflCRdffXV+sEPfqDrrrtO9957r3bv3q2vf/3ruuaaa1RcXCxJuvfeezVz5kz169dP06dPV0NDg95++219/etfP7IvFACQVghXAIBe5z//+Y/69++fcGzkyJH6+OOPJVmd/J555hnddNNNKikp0Z/+9CeNGTNGkpSZmalXXnlF3/jGN3TyyScrMzNTl19+uR588MHYY1133XVqbW3VQw89pDvuuENFRUW64oorjtwLBACkJboFAgCOKoZh6MUXX9Sll16a6qEAAHoZ1lwBAAAAQA8gXAEAAABAD2DNFQDgqMJseADA4ULlCgAAAAB6AOEKAAAAAHoA4QoAAAAAegDhCgAAAAB6AOEKAAAAAHoA4QoAAAAAegDhCgAAAAB6AOEKAAAAAHoA4QoAAAAAesD/B6U1zGO9vy/NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(range(N_EPOCHS), history.history['loss'], label='train loss')\n",
    "plt.plot(range(N_EPOCHS), history.history['val_loss'], label='validation loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c53d1579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 516us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.346833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.872389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.554532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.654982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.937938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.047797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.410627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.387032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.767797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.346833\n",
       "1    0.975709\n",
       "2    0.872389\n",
       "3    0.554532\n",
       "4    0.654982\n",
       "..        ...\n",
       "995  0.937938\n",
       "996 -0.047797\n",
       "997  0.410627\n",
       "998  0.387032\n",
       "999  0.767797\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_x)\n",
    "df = pd.DataFrame(pred)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aa2b491c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.073463\n",
       "1      0.824888\n",
       "2      0.726801\n",
       "3      0.103462\n",
       "4      0.479768\n",
       "         ...   \n",
       "495    0.838311\n",
       "496    0.310638\n",
       "497    0.997561\n",
       "498    0.910411\n",
       "499    0.904922\n",
       "Name: eyeRotation, Length: 500, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tey_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2c447dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1877056541401249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(tey_eye, pred)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b46d9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1499556158609646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(tey_eye, pred)\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
